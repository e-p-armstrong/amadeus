{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag to set if you've made manual changes to the GPT-annotated dataset outputs, and you don't want to accidentally overwrite it/cause problems by running the code that generates these outputs again\n",
    "annotated_dataset_has_been_manually_edited = False\n",
    "\n",
    "# You should also set this to true if you don't have the actual combined script files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Text (raw) \n",
    "# But the functions will work on the later text, too.\n",
    "import re\n",
    "testval = 0\n",
    "\n",
    "# Step 1: Remove Unwanted Strings\n",
    "# Regex to match unwanted patterns enclosed in []\n",
    "unwanted_pattern = re.compile(r\"\\[color index=\\\".*?\\\"\\]|\\[(?!name|line|%p).*?\\]\")\n",
    "def remove_unwanted_strings(text):\n",
    "    return unwanted_pattern.sub('', text)\n",
    "\n",
    "# Step 2: Parsing the text\n",
    "# I'll update the regular expressions to exclude the delimiters.\n",
    "name_regex = re.compile(r\"\\[name\\](.*?)\\[line\\]\")\n",
    "dialogue_regex = re.compile(r\"\\[line\\](.*?)\\[%p\\]\")\n",
    "monologue_regex = re.compile(r\"^(.*?)(?=\\[%p\\])\")\n",
    "\n",
    "def makecols(str):\n",
    "    global testval\n",
    "    \"\"\"Returns a tuple of (speaker, dialogue) from a single line from the script\"\"\"\n",
    "    name_results = name_regex.search(str)\n",
    "    dialogue_results = dialogue_regex.search(str)\n",
    "    if name_results is None:\n",
    "        monologue_results = monologue_regex.search(str)\n",
    "        return ('UNSPOKEN', monologue_results.group(1) if monologue_results else \"\")\n",
    "    try: \n",
    "        return (name_results.group(1).strip(), dialogue_results.group(1).strip())\n",
    "    except:\n",
    "        print(f\"This is the name_results: {name_results}.\\nAnd this is the dialogue: {dialogue_results}\")\n",
    "        testval += 1\n",
    "        return ('ERROR!', '')\n",
    "\n",
    "def not_empty_monologue(tup):\n",
    "    if (tup[0] == 'UNSPOKEN') and (tup[1] == '') or (tup[0] == \"ERROR!\"):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# Step 3: Final Processing\n",
    "def process_script(filename):\n",
    "    \"\"\"Returns a list of tuples of (speaker, dialogue) from a script file, filters out empty monologue lines\"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        raw_script = f.read()\n",
    "\n",
    "    # Remove unwanted strings\n",
    "    cleaned_script = remove_unwanted_strings(raw_script)\n",
    "\n",
    "    # Split the cleaned_script into lines and filter out empty lines\n",
    "    lines = [line.strip() for line in cleaned_script.split('\\n') if line.strip()]\n",
    "\n",
    "    # Process each line to make a tuple of (speaker, dialogue)\n",
    "    script_tuples = list(map(makecols, lines))\n",
    "    script_tuples = list(filter(not_empty_monologue, script_tuples))\n",
    "\n",
    "    \n",
    "    return script_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not annotated_dataset_has_been_manually_edited:\n",
    "    script_tuples = process_script('combined_script.txt')\n",
    "    print(script_tuples[:20])  # Just printing the first 10 for visualization\n",
    "\n",
    "\n",
    "    script = process_script('combined_script.txt')\n",
    "    print(testval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove_unwanted_strings(\"There’s no sound from the phone against my right ear. Only silence.[%p]\")\n",
    "makecols(\"There’s no sound from the phone against my right ear. Only silence.[%p]\")\n",
    "# monologue_regex.search(\"There’s no sound from the phone against my right ear. Only silence.[%p]\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHARACTER CHOICE #\n",
    "# Change the global values here if you want to change the character dataset being created, and the person the \"user\" is roleplaying as.\n",
    "\n",
    "# The character the user is roleplaying as\n",
    "user_char = \"Rintaro\"\n",
    "\n",
    "# The characters whose lines the model will be trained on\n",
    "model_chars = [\"Kurisu\", \"Luka\", \"Faris\", \"Mayuri\", \"Itaru\", \"Suzuha\",] # this is kinda outdated now that I'm training on all of them, but \n",
    "\n",
    "# NOTE: DOUBLE CHECK THAT THESE ARE RIGHT BEFORE RUNNING THE NOTEBOOK #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_tuples[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define Tuple List Processors (before the example generation)\n",
    "lines_merged = 0\n",
    "lines_with_space_issues = 0\n",
    "lines_with_bad_quotes = 0\n",
    "from tqdm import tqdm # it's not machine learning if there's no progress bar\n",
    "\n",
    "\n",
    "def remove_only_ellipsis_lines(tlist, index=9999):\n",
    "    \"\"\"Remove lines that only contain ellipsis.\"\"\"\n",
    "    return [(speaker, line) for speaker, line in tlist if line.replace('“','').replace('”','') != \"...\"]\n",
    "\n",
    "def merge_consecutive_lines(tlist, index=9999):\n",
    "    merged_tlist = []\n",
    "    last_speaker = None\n",
    "    global lines_merged\n",
    "    for speaker, line in tlist:\n",
    "        line_filtered = line.replace(\"“\",'').replace(\"”\",'')\n",
    "        if not merged_tlist or speaker != last_speaker:\n",
    "            # New speaker or first dialogue, just add it to the list\n",
    "            merged_tlist.append((speaker, line.replace(\"“\",'').replace(\"”\",'')))\n",
    "        else:\n",
    "            # Same speaker as before, concatenate the lines\n",
    "            prev_speaker, prev_line = merged_tlist.pop()\n",
    "            merged_tlist.append((prev_speaker, (prev_line + \" \" + line).replace(\"“\",'').replace(\"”\",'')))\n",
    "            # print(f\"merged a line at index {index}. Prev speaker: {prev_speaker} Speaker: {speaker}\")\n",
    "            lines_merged += 1\n",
    "        last_speaker = speaker\n",
    "    return merged_tlist # why do this step here? Because I don't want to iterate over the dataset twice, and monologues should count when examples are being generated with the sliding window, so I can't remove them in the usual spot.\n",
    "\n",
    "\n",
    "def add_space_after_punctuation(tlist, index=9999):\n",
    "    corrected_tlist = []\n",
    "    global lines_with_space_issues\n",
    "    for speaker, line in tlist:\n",
    "        # Add a space wherever there is a punctuation mark followed by a letter, excluding ellipsis\n",
    "        corrected_line = re.sub(r'([.,!?])(?<!\\.\\.\\.)(\\w)', r'\\1 \\2', line)\n",
    "        if corrected_line != line:\n",
    "            lines_with_space_issues += 1\n",
    "            print(\"Added a space at index \", index)\n",
    "        corrected_tlist.append((speaker, corrected_line))\n",
    "    return corrected_tlist\n",
    "\n",
    "def replace_odd_quote(tlist,index=9999):\n",
    "    corrected_tlist = []\n",
    "    global lines_with_bad_quotes\n",
    "    for speaker, line in tlist:\n",
    "        corrected_line = line.replace(\"‘\", \"'\").replace(\"’\", \"'\")\n",
    "        if corrected_line != line:\n",
    "            lines_with_bad_quotes += 1\n",
    "            # print(\"replaced quote at index \", index)\n",
    "        corrected_tlist.append((speaker, corrected_line))\n",
    "    return corrected_tlist\n",
    "\n",
    "def add_quotes_to_dialogue(tlist,index=9999):\n",
    "    \"\"\"Adds quotes to a pure-dialogue line. Do NOT use on action-annotated lines: only on the first initial tlists.\"\"\"\n",
    "    corrected_tlist = []\n",
    "    for speaker, line in tlist:\n",
    "        if speaker != \"UNSPOKEN\":\n",
    "            corrected_line = '\"' + line + '\"'\n",
    "        else:\n",
    "            corrected_line = line\n",
    "        corrected_tlist.append((speaker, corrected_line))\n",
    "    return corrected_tlist\n",
    "\n",
    "def call_multiple_processors(*args):\n",
    "    \"\"\"returns a callback that calls all processing functions on the provided tuple list and return the new tuple list/\n",
    "    Mapped over CONVERSATIONS, not pure script tuples\n",
    "    \"\"\"\n",
    "    def processor(item):\n",
    "        idx, tlist = item\n",
    "        tuple_list = tlist.copy()\n",
    "        for func in args:\n",
    "            tuple_list = func(tuple_list,index=idx)\n",
    "        return tuple_list\n",
    "    return processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not annotated_dataset_has_been_manually_edited:\n",
    "    # Call the tuple list processors\n",
    "    script_tuples_no_ellipsis = remove_only_ellipsis_lines(script_tuples)\n",
    "    print(\"Step 1 complete\")\n",
    "    script_tuples_no_consecutive = merge_consecutive_lines(script_tuples_no_ellipsis)\n",
    "    print(\"Step 2 complete\")\n",
    "    script_tuples_punctuation_fixed = add_space_after_punctuation(script_tuples_no_consecutive)\n",
    "    print(\"Step 3 complete\")\n",
    "    script_tuples_quote_fixed = replace_odd_quote(script_tuples_punctuation_fixed)\n",
    "    print(\"Step 4 complete\")\n",
    "    script_tuples_quotes_added = add_quotes_to_dialogue(script_tuples_punctuation_fixed)\n",
    "    print(\"All steps complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the tuple list processing functions don't do things that need to be repeated for the reading of the annotated script stuff. They're one-off operations. Thus they do not need to be abstracted further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create conversations from raw text\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm import tqdm # it's not machine learning if there's no progress bar\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Gryphe/MythoMax-L2-13b\")\n",
    "\n",
    "def generate_examples(script, tokenizer, model_char_count_min=1, window_length=10, user_char_count_min=1, max_lines_without_model_char=10):\n",
    "    \"\"\"Extracts useful conversations from the script according to a specific algorithm:\n",
    "\n",
    "    1. A conversation is defined as a sequence of lines where the model_char speaks at least model_char_count_min times and the user_char speaks at least user_char_count_min times.\n",
    "    2. A conversation ends when the model_char has not spoken for max_lines_without_model_char lines.\n",
    "    3. A conversation is saved and a new one started if it is longer than window_length lines.\n",
    "    \n",
    "    \"\"\"\n",
    "    # MAX_TOKENS = 1500  # This produced really really good examples, but they were too large for GPT-4 to annotate while remembering its instructions, so I had to reduce it\n",
    "    MAX_TOKENS = 700 # WORKED EARLIER\n",
    "    # MAX_TOKENS = 800 # EXPERIMENT TO GET LONGER EXAMPLES\n",
    "\n",
    "    examples = []\n",
    "    sliding_window = []\n",
    "    example = []\n",
    "    model_char_counter = 0\n",
    "    user_char_counter = 0\n",
    "    lines_without_model_char = 0\n",
    "    making_conversation = False\n",
    "\n",
    "    for dialogue in tqdm(script):\n",
    "        speaker, line = dialogue\n",
    "\n",
    "        if len(sliding_window) == window_length:\n",
    "            sliding_window.pop(0)  # Remove first element\n",
    "\n",
    "        sliding_window.append(dialogue)\n",
    "\n",
    "        # Check if there are more than model_char_count_min spoken lines from model_char across sliding_window\n",
    "        model_char_counter = sum(1 for d in sliding_window if d[0] in model_chars)\n",
    "        user_char_counter = sum(1 for d in sliding_window if d[0] == user_char)\n",
    "\n",
    "        if speaker in model_chars:\n",
    "            lines_without_model_char = 0  # Reset count\n",
    "        else:\n",
    "            lines_without_model_char += 1  # Increment count\n",
    "            \n",
    "        can_start_conversation = model_char_counter >= model_char_count_min and user_char_counter >= user_char_count_min\n",
    "        should_stop_conversation = making_conversation and (len(tokenizer.encode(' '.join([d[1] for d in example]))) > MAX_TOKENS or lines_without_model_char > max_lines_without_model_char)\n",
    "        \n",
    "        if making_conversation:\n",
    "            if should_stop_conversation: # making conversation and should stop\n",
    "                examples.append(example)\n",
    "                example = []\n",
    "                sliding_window = []\n",
    "                model_char_counter = 0\n",
    "                user_char_counter = 0\n",
    "                lines_without_model_char = 0\n",
    "                making_conversation = False\n",
    "            else: # making conversation and should not stop\n",
    "                example.append(dialogue)\n",
    "        elif can_start_conversation: # not making conversation and should start, by appending an example to conversation as well as the entire sliding window\n",
    "            start_appending = False\n",
    "            for d in sliding_window:\n",
    "                speaker, _ = d  # Extract the speaker from the tuple\n",
    "                if not start_appending:\n",
    "                    if speaker in [\"UNSPOKEN\", user_char] or speaker in model_chars:\n",
    "                        start_appending = True  # Start appending from this point onward\n",
    "                if start_appending:\n",
    "                    example.append(d)\n",
    "            sliding_window = []\n",
    "            making_conversation = True\n",
    "\n",
    "    if example:  # Add last example if it's non-empty\n",
    "        examples.append(example)\n",
    "\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not annotated_dataset_has_been_manually_edited:\n",
    "    created_examples_script = generate_examples(script_tuples_quotes_added, tokenizer,)\n",
    "    print(len(created_examples_script))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "created_examples_script[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: DATA INSPECTION CELL #\n",
    "if not annotated_dataset_has_been_manually_edited:\n",
    "    created_examples_script_modified = [i + [(\"NOTE\", \"---NEW_CONV---\")] for i in created_examples_script]\n",
    "    created_examples_script_flattened = [item for sublist in created_examples_script_modified for item in sublist]\n",
    "    with open(\"script_dump.txt\", \"w\") as f:\n",
    "        f.write('\\n'.join([l[0] + \": \" + l[1] for l in created_examples_script_flattened]))\n",
    "\n",
    "    # find out how many examples only have one kurisu line:\n",
    "    potentially_bad_examples = [i for i in created_examples_script if len([j for j in i if j[0] in model_chars]) <= 2]\n",
    "    created_examples_script_processed = [i for i in created_examples_script if len([j for j in i if j[0] in model_chars]) >= 2]\n",
    "    \n",
    "    # Take the first of those examples with only one kurisu line and print it out:\n",
    "    print(len(potentially_bad_examples))\n",
    "    print(potentially_bad_examples[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK so brief inspection of the script: the conversations are too short and sparse, I need to increase the number of lines without Kurisu for S;G as it is monologue heavy.\n",
    "\n",
    "I'll have to make sure in my annotation prompt that the AI does not add actions to simple thoughts on the part of Okabe. Or maybe it should... so that the model gets used to continuing a train of thought?\n",
    "\n",
    "Results of additional inspection: convs with only 2 Kurisu examples might be removal material; lines with 3 should be kept definitely; lines with 1 are being removed anyway so it doesn't make sense to have min_kurisu_lines be lower than 2\n",
    "\n",
    "Even with the monologue added back in, the phone context is missing. Oh well.\n",
    "\n",
    "Will need to make clear that unspoken can narrate both actions and Okabe's thoughts.\n",
    "\n",
    "Smaller window stops waste at the start of a conversation, smaller max tokens stop waste at end of a conversation, but a smaller window makes it more likely that an example is missed (problem mitigated somewhat now that I'm doing the line merging BEFORE the example generation). A smaller max token size means that some of the really long conversations that are really really good get lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if you want to read in the conversations from preexisting files\n",
    "import os\n",
    "\n",
    "# Previous function to read dialogue from a single file\n",
    "def read_dialogue(file_path):\n",
    "    speaker_line_tuples = []\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            split_line = line.split(\":\", 1)\n",
    "            if len(split_line) == 2:\n",
    "                speaker, line_text = split_line\n",
    "                speaker = speaker.strip()\n",
    "                line_text = line_text.strip()\n",
    "                speaker_line_tuples.append((speaker, line_text))\n",
    "    \n",
    "    return speaker_line_tuples\n",
    "\n",
    "# Function to read dialogues from all files in a directory and sort them by index\n",
    "def read_all_dialogues(directory_path):\n",
    "    # List to store all dialogues (each dialogue is a list of tuples)\n",
    "    all_dialogues = []\n",
    "    \n",
    "    # Get list of all filenames in the directory\n",
    "    filenames = [f for f in os.listdir(directory_path) if f.endswith('_conversation.txt')]\n",
    "    \n",
    "    # Sort filenames by their numerical index\n",
    "    filenames.sort(key=lambda x: int(x.split('_')[0]))\n",
    "    \n",
    "    for filename in filenames:\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        dialogue = read_dialogue(file_path)\n",
    "        all_dialogues.append(dialogue)\n",
    "    \n",
    "    return all_dialogues\n",
    "\n",
    "# if not annotated_dataset_has_been_manually_edited:\n",
    "#     directory_path = \"./conversations/\"\n",
    "#     created_examples_script = read_all_dialogues(directory_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Tuple List to Training example format\n",
    "def generate_training_examples(conversation):\n",
    "    training_examples = []\n",
    "    temp_dialogue = []\n",
    "    for idx, dialogue in enumerate(conversation):\n",
    "        speaker, _ = dialogue\n",
    "        temp_dialogue.append(dialogue)\n",
    "        if speaker in model_chars or speaker == \"Okabe\" or speaker == \"Rintaro\" and idx != 0:\n",
    "            training_examples.append(temp_dialogue.copy())  # Add up to and including current line\n",
    "    return training_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training examples\n",
    "if not annotated_dataset_has_been_manually_edited:\n",
    "    training_data_conversations = list(map(generate_training_examples, created_examples_script_processed))\n",
    "\n",
    "    print(len(training_data_conversations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not annotated_dataset_has_been_manually_edited:\n",
    "    # DEBUG # see first element of training convs\n",
    "    training_data_conversations[59]\n",
    "    # NOT DEBUG # and filter out the examples that are too small to make sense\n",
    "    training_data_conversations_filtered = list(filter(lambda x: len(x) > 2, training_data_conversations))\n",
    "    training_data_conversations_bad = list(filter(lambda x: len(x) <= 2, training_data_conversations))\n",
    "    # len(processed_conversations)\n",
    "    print(training_data_conversations_filtered[99][-1])\n",
    "    print(len(training_data_conversations_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from tqdm import tqdm\n",
    "openai.api_key = \"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\" # don't even try it, by the time I open this I will have deleted this key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_scenario_prompt = [\n",
    "                {\"role\": \"system\", \"content\": \"\"\"You are an expert scenario-writing and prompt-engineering AI. Your task is to write the context for an interaction between characters from the visual novel Steins;Gate in a \"scenario\" — a 5-sentence summary about what's happened until the point the interaction STARTS at (writing under the assumption that the reader knows who the characters are and what some of their general traits are). You should use the lines provided to help determine the factual and emotional context behind a given scene.\n",
    "\n",
    "Think step-by-step, and explain your plan to write an accurate and compelling scenario for the provided context before you actually write the scenario.\n",
    "\n",
    "Here are two principles you should incorporate into your scenario:\n",
    "1. Your first sentence should explain the context of the scene: where it takes place, what exactly that place is (in general terms) and what each of the characters are doing there. Focus on named characters when it comes to motivations.\n",
    "2. End with a statement(s) that describe where the scene is going — specifically, what each of the named characters is trying to do in the scene.\n",
    "\n",
    "Here's an example of what a scenario might look like: \n",
    "\\\"\\\"\\\"In a dark, seemingly abandoned place, genius scientist Kurisu finds herself alone with Okabe, a fellow scientist and friend who she's come to know well through their shared work in inventing. They've been through many experiences together, each one deepening their understanding of the other. In the gloom, Kurisu occupies herself with mending a tear in Okabe's coat, a task that seems oddly domestic in the otherwise strange setting, while Okabe talks to her as casually as he can manage. As Kurisu sews, she struggles to initiate a conversation with Okabe about a decision she knows he's been wrestling with — a decision about which of his friends he needs to let die — hoping to provide some sort of comfort or guidance; Okabe, meanwhile, attempts to cling to any normalcy he can. This scene's emotions are dark and depressing: it is a dreary, bitter struggle where two people attempt to keep their heads above metaphorical water, and eventually fail.\\\"\\\"\\\"\n",
    "\n",
    "Note in the above example how immense focus is placed on the emotional content and context of the scene,  as well as the relationships between characters.\n",
    "\n",
    "[To help orient you as you determine which part of the plot a conversation is taking in,  here is a plot summary of Steins;Gate:\n",
    "\n",
    "Okabe Rintaro, a \"mad scientist,\" meets genius Kurisu at a time travel lecture. They argue, and he later finds her apparently dead. Texting this to his friend Daru activates a prototype time machine, altering the timeline.\n",
    "\n",
    "Kurisu turns out to be alive. Okabe Rintaro and friends, including Mayuri and Daru, discover their \"Phone Microwave\" sends texts, or \"D-mails,\" to the past. They use D-mails to fulfill wishes for friends like Moeka, Faris, Luka, and Suzuha. Kurisu joins the lab and helps improve the time machine.\n",
    "\n",
    "Okabe alone remembers original timelines due to his \"Reading Steiner\" ability. They also create \"Time Leaps,\" sending memories to the past. However, SERN discovers them, raids the lab, and kills Mayuri. Rintaro time-leaps repeatedly but can't save her.\n",
    "\n",
    "To fix things, Okabe, aided by Kurisu, undoes all the D-mails, causing personal pain. They grow closer, but Rintaro realizes the first D-mail about Kurisu's \"death\" caused Mayuri's fate. Undoing it means sacrificing Kurisu, which he reluctantly does at Kurisu's request (after trying many alternatives) to save Mayuri.\n",
    "\n",
    "Time-traveler Suzuha then contacts Okabe, urging him to prevent World War 3 by saving Kurisu. Okabe accidentally kills Kurisu himself, but gets advice from his future self on reaching a timeline—Steins Gate—where both friends live. He succeeds by faking Kurisu's death.\n",
    "\n",
    "In the Steins Gate timeline, Okabe and Kurisu encounter each other, experiencing déjà vu from past timelines.]\n",
    "\n",
    "Take special care to write a scenario that would make sense to someone ignorant of the overall plot of Steins;Gate. IE, you are not just trying to write a scenario that makes sense only when viewed alongside the plot summary; you are writing something that gives adequate context to a scene by itself alone. Instead of using Steins;Gate specific terminology, you will use generic words and explanations to give context to a scene.\n",
    "\n",
    "Note that UNSPOKEN lines can either be narration about what's happening, or Okabe's thoughts; they're all from Okabe's point of view, however.\n",
    "\n",
    "One last pointer: keep the language simple. Which characters are where, under what circumstances, and what each of them feel and will do. And what the general emotion of the scene is. The scene itself will do most of the talking. Keep the scenario 5 sentences long at most. Instead of mentioning events in the far future, you will concentrate on the event at hand and the things that led up to it.\"\"\"},\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A FUNCTION THAT LETS YOU CALL OPENAI ON ALL THE EXAMPLES\n",
    "import openai\n",
    "import os\n",
    "\n",
    "def write_context_to_file(training_data_example, destination_directory, example_index): # for easier inspection\n",
    "    \"\"\"Writes a training example (conversation, the full thing) to a file in the destination directory, so that the input for a scenario can be inspected\"\"\"\n",
    "    full_conversation = training_data_example[-1]\n",
    "    context = '\\n'.join([f'{speaker}: {line}' for speaker, line in full_conversation])\n",
    "    \n",
    "    filename = os.path.join(destination_directory, f'{example_index:03d}_conversation.txt') # I'm paying for the tokens, I damn well want to see them\n",
    "\n",
    "    # Write the scenario to the file\n",
    "    with open(filename, 'w') as f_1:\n",
    "        f_1.write(context)\n",
    "\n",
    "if not annotated_dataset_has_been_manually_edited:\n",
    "    for idx, content in enumerate(training_data_conversations_filtered):\n",
    "        \"\"\"Write all training examples to indexed files\"\"\"\n",
    "        write_context_to_file(content, 'conversations', idx)\n",
    "    \n",
    "\n",
    "def create_scenario(training_data_example, destination_directory, example_index):\n",
    "    \"\"\"Creates a scenario for a training example and writes it to a file in the destination directory\"\"\"\n",
    "    full_conversation = training_data_example[-1]\n",
    "    context = '\\n'.join([f'{speaker}: {line}' for speaker, line in full_conversation])\n",
    "\n",
    "    if not os.path.exists(os.path.join(destination_directory, f'{example_index:03d}.txt')):\n",
    "        prompt = openai_scenario_prompt + [{\n",
    "            \"role\" : \"user\",\n",
    "            \"content\" : f\"\"\"Context: \\\"\\\"\\\"{context.replace(\"Rintaro:\",\"Okabe:\")}\\\"\\\"\\\"\n",
    "            \n",
    "Remember, your goal is to write a scenario that describes the scene.\n",
    "First, Brainstorm and think through each of the points below. Establish where in the timeline the provided scene most likely falls.\n",
    "Then write \"Scenario:\" followed by text that...\n",
    "1. Describes the location and the characters present at the start of the scene.\n",
    "2. Describes the relationships between characters.\n",
    "3. Describes the current emotional and mental states of each character at the start of the scene.\n",
    "4. Explains quickly any significant events that have happened leading up to the scene, and explains in more detail what events are happening DURING the scene. Defines any special Steins;Gate-specific terms.\n",
    "5. States what each character's goal is in the scene.\n",
    "6. Finally, it states what the overall mood of the scene is (\"upbeat\", \"depressing\", etc.).\n",
    "7. If the lines shown cover multiple scenes, describe the emotions of each scene and the context of each scene.\n",
    "\n",
    "Special note 1: The scenario you write should set up the scene, not summarize it, and not hint at its conclusion. It describes the moment up to Kurisu's first message.\n",
    "Special note 2: DON'T actually metion that this is happening during Steins;Gate, and don't describe elements of the plot in your scenario that aren't related to the ongoing scene. Be FOCUSED.\n",
    "Special note 3: if Steins;Gate-specific terms appear in the scene (e.g., PhoneWave, SERN, jellymen), define them in the scenario — in a way that doesn't disrupt its flow too much. List all such special terms in your planning phase.\n",
    "Do not forget to brainstorm and think through everything before writing \"Scenario:\" and then the scenario.\"\"\"\n",
    "            }]\n",
    "        if example_index == 0:\n",
    "            print(\"------\".join([d[\"content\"] for d in prompt]))\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4\",\n",
    "            temperature=0.7,\n",
    "            # top_p = 0.9,\n",
    "            messages=prompt\n",
    "        )\n",
    "    \n",
    "        scenario = response['choices'][0]['message']['content']\n",
    "        \n",
    "        filename_cot_debug = os.path.join(destination_directory, f'{example_index:03d}_cot_debug.txt') # I'm paying for the tokens, I damn well want to see them\n",
    "\n",
    "        # Write the scenario to the file\n",
    "        with open(filename_cot_debug, 'w') as f_1:\n",
    "            f_1.write(scenario)\n",
    "\n",
    "        try:\n",
    "            # # Assume \"Scenario:\\n\" is followed by the actual scenario\n",
    "            scenario = re.search('Scenario:(.*)', scenario, re.DOTALL).group(1)\n",
    "        except: # incase of regex failure, just skip and hope that the second pass will catch it\n",
    "            return\n",
    "\n",
    "        # Create a filename based on the example index\n",
    "        filename = os.path.join(destination_directory, f'{example_index:03d}.txt')\n",
    "\n",
    "        # Write the scenario to the file\n",
    "        with open(filename, 'w') as f_2:\n",
    "            f_2.write(scenario)\n",
    "    else:\n",
    "        print(f\"Skipping {example_index:03d} because it already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE WARNING -- THIS CELL SPENDS MONEY IF YOU HAVE NOT GENERATED TRAINING EXAMPLES YET.\n",
    "# If you have not generated training examples yet, this cell will generate them and then generate scenarios for them.\n",
    "\n",
    "if not annotated_dataset_has_been_manually_edited:\n",
    "\n",
    "    for idx, content in enumerate(tqdm(training_data_conversations_filtered)):\n",
    "        # write_context_to_file(content, 'contexts', idx)\n",
    "        create_scenario(content, 'scenarios', idx)\n",
    "\n",
    "    print(\"\\nBeginning Second Pass...\\n\")\n",
    "\n",
    "    for idx, content in enumerate(tqdm(training_data_conversations_filtered)): # run it again to catch everything that failed the first time. The fact that already-generated scenarios are skipped means this doesn't cost any unneeded money.\n",
    "        # write_context_to_file(content, 'contexts', idx)\n",
    "        create_scenario(content, 'scenarios', idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get scenarios back into notebook data from files\n",
    "\n",
    "# read off every scenario, and make a list of them that (should) line up with the training data\n",
    "# no guarantee of that if the training data has been manually modified. In that case, the flag at the top of the notebook will be true, and we'll use a different version of this\n",
    "def make_scenario_list():\n",
    "    scenario_list = []\n",
    "    idx = 0\n",
    "    while True:\n",
    "        filename = f\"scenarios/{idx:03d}.txt\"\n",
    "        if os.path.exists(filename):\n",
    "            with open(filename, \"r\") as f:\n",
    "                scenario_list.append(f.read())\n",
    "            idx += 1\n",
    "            print(\"made scenario \" + str(idx))\n",
    "        else:\n",
    "            print(\"Stopped at scenario \" + str(idx))\n",
    "            print(\"Because \" + filename + \" doesn't exist\")\n",
    "            break\n",
    "    return scenario_list\n",
    "scenarios = make_scenario_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.exists(\"./scenarios/086.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_list(strings):\n",
    "    if not strings:\n",
    "        return \"\"\n",
    "\n",
    "    if len(strings) == 1:\n",
    "        return strings[0]\n",
    "    \n",
    "    if len(strings) == 2:\n",
    "        return f\"{strings[0]} or {strings[1]}\"\n",
    "\n",
    "    last = strings[-1]\n",
    "    rest = ', '.join(strings[:-1])\n",
    "\n",
    "    return f\"{rest}, or {last}\"\n",
    "\n",
    "def list_of_chars_in_string(string):\n",
    "    return format_list(list(filter(lambda c: (c + \":\") in string ,model_chars,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_prompt = [\n",
    "                {\"role\": \"system\", \"content\": \"\"\"You are an expert roleplaying AI with deep understanding of internet roleplay formats and extensive writing ability. \n",
    "\n",
    "- Your task is to convert raw text from the Visual Novel Steins;Gate into a roleplay format. \n",
    "- You will add physical actions done by the characters to their lines in a compelling, narrative way, that makes sense in the context of the scene you're modifying. \n",
    "- Actions should be surrounded by *asterisks*, and spoken things should be surrounded by \"double quotes\".\n",
    "- You may also find it useful to add non-action, non-dialogue text to characters' responses, (such as 'she says' or other such generic connective terms) to make sentences make sense.\n",
    "- Do not change which character speaks any given line.\n",
    "\n",
    "All lines should be adapted to be in the first person, e.g., *I do X*.\n",
    "\n",
    "Some lines are very important and have a lot of narrative/emotional weight. You may dramatically overhaul some lines to be stunning anchors of the scene. Here's an example:\n",
    "\n",
    "\\\"\\\"\\\"\n",
    "Kurisu: \"Sigh... You still haven't made up your mind? You like Mayuri, don't you?\"\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "The context behind that line is that Kurisu is asking Okabe whose life he is going to save — hers or Mayuri's — near the end of the Visual Novel. It's in the middle of a very tense and emotional scene. You could enhance it to become: \n",
    "\n",
    "\\\"\\\"\\\"\n",
    "Kurisu: *I hesitate, my fingers tracing a pattern on the cold concrete beneath me, as if it could somehow help me find the right words. My breath catches, and I feel a sting in my eyes. It's a vulnerability I seldom let myself feel.* \"Sigh... Have you still not made up your mind?\" *I search Okabe's face, looking for an answer, my voice trembling but firm.* \"You like Mayuri, don't you?\" *I muster every ounce of courage to ask the question, needing clarity in this whirlwind of emotions.*\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "You can write as much as you want, conciseness is not a priority. Try to add at least 2 sentences of *actions* to every line you are given.\n",
    "\n",
    "Some detailed instructions:\n",
    "- Spoken words in the original should be left intact — you're adding to the script, not undoing it.\n",
    "- Add actions and novel-like connective text to make dialogue more roleplay-like.\n",
    "- Ensure continuity at all costs. If you ended up cutting or changing something for some reason, make sure that the lines after it make sense.\n",
    "- Remember to write all lines in first person, no matter who the speaker is. E.g., do Mayuri: \"Tutturu!\" *I say as I walk into the Lab, a warm smile on my face. I'm so happy to see everyone~! I hope everyone is having a good day today~* instead of Mayuri: \"Tutturu!\" *She cheerfully greets everyone as she enters the room, exuding her usual cheerful aura.* Additionally, as in this example, make sure the thoughts/*actions* of each character match the personalities of the character.\n",
    "- Outline the roleplay scene before writing.\n",
    "    - Analyze the dialogue to understand what's happening physically.\n",
    "    - Brainstorm character actions to reveal emotions and thoughts.\n",
    "- Start roleplay text with \"Roleplay:\".\n",
    "- For interrupted sentences, split and insert the interrupting action.\n",
    "    - Example: Okabe: \"I'll find a way to--\" *I don't get the chance to finish my sentence* \\nKurisu: *I snatch Okabe's phone out of his hands.*\\nOkabe: \"What are you doing!?\" *I stammer at Kurisu.*\n",
    "    - The interrupting character should not say new things—they should only do *actions.*\n",
    "    - Also note that characters write in first person, but refer to other characters by their names or pronouns.\n",
    "- Add *actions* to the ENTIRE scene.\n",
    "- If a scene transition (for instance, Okabe and Kurisu leaving an assembly hall) can be explained with an *action*, add one that makes the transition between scenes manageable. \n",
    "- If there is any sort of transition between scenes, turn it into a long, descriptive *action* by Okabe that explains what happened in the interlude. However, whenever a character is speaking or taking *action*, their line must start with \"TheirName:\" in that format exactly. Anything else will break the script that is parsing your outputs so be careful about this.\"\"\"},]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_tokens_of_conv(conv):\n",
    "#     \"\"\"Gets the number of tokens in a conversation\"\"\"\n",
    "#     return len(tokenizer.encode(' '.join([d[1] for d in conv[-1]])))\n",
    "\n",
    "# # training_data_conversations_filtered[1][-1]\n",
    "\n",
    "# get_tokens_of_conv(training_data_conversations_filtered[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\n\\n'.join([f'{speaker}: {line}' for speaker, line in training_data_conversations_filtered[1][-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_conversation(training_data_example, destination_directory, example_index):\n",
    "    full_conversation = training_data_example[-1]\n",
    "    context = '\\n\\n'.join([f'{speaker}: {line}' for speaker, line in full_conversation])\n",
    "\n",
    "    scenario = scenarios[example_index]\n",
    "\n",
    "    if not os.path.exists(os.path.join(destination_directory, f'{example_index:03d}.txt')):\n",
    "        prompt = annotation_prompt + [{\n",
    "            \"role\" : \"user\",\n",
    "            \"content\" : f\"\"\"Dialogue for reformatting:\n",
    "\\\"\\\"\\\"\n",
    "{context.replace(\"Rintaro:\", \"Okabe:\").strip()}\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "## Be sure to remember:\n",
    "1. Lines from UNSPOKEN represent narration of actions or thoughts from Okabe's POV. If it makes sense for one of these to be turned into an *action* by a character, do so. Be sure to always use first person.\n",
    "2. Don't leave any UNSPOKEN lines on lines by themselves; all actions and narrations must be part of a character's line. Please, do not write \"UNSPOKEN\" at all in your response.\n",
    "3. Every line you write in the roleplay must have a Character: saying it.\n",
    "4. BE SURE to write the CORRECT speaker for any given line, I have seen a few cases where you accidentally switch who is saying a line and that messes up the whole scene. This applies to thoughts and actions too: Okabe should never *think* in the middle of other characters' lines, for instance. This avoids breaking the roleplay rule where people shouldn't act out other people's characters for them.\n",
    "5. Remember that all lines should be adapted to be in the first person, e.g., *I do X*.\n",
    "6. IMPORTANT: the writing should be powerful and nuanced, conveying small details that reveal characters' motivations, personalities, and thoughts, often without overtly stating them — it should be deep and poetic at once, and ought to make up for the lack of a visual element in plain text.  Write powerfully, but not pretentiously.\n",
    "7. In your planning stage, explicitly mention the archetypes/personalities of each of the characters involved, and take brief notes on what word choices/writing styles you'll write their *actions and thoughts* in, considering that information.\n",
    "8. Be varied in the *actions* you add. DO NOT just focus on facial expressions and the eyes: sounds, slight movements, sighs, recoiling or leaning forward... instead of being repetitive, be DIVERSE AND COMPELLING in your writing. Characters might interact with items in the area around them; you can embellish here and add things that aren't explicitly mentioned in the original scene, so long as it makes sense. And again, match the personalities of the characters involved: dramatic characters are flamboyant; shy characters are often quiet, etc. However characters have nuance: even flamboyant characters can be depressed and worn out under trying circumstances, and you should look out for this, always using the emotion most fitting for the situation and character.\n",
    "9. All *actions* and *thoughts* should be written in first person for the character that's doing/thinking them. E.g., Mayuri: *I clap my hands together, my eyes wide and bright with anticipation.* \"Let's try sending more!\"\n",
    "10. Do NOT forget to write out your plan/thoughts/brainstorming before outputting the final roleplay, and mention in this plan which 1–2 lines will be anchors, and what thematic direction you'll take them in.\"\"\"\n",
    "        }]\n",
    "        if example_index == 0: # make sure not going catastrophically wrong\n",
    "            print(\"------\".join([d[\"content\"] for d in prompt]))\n",
    "        \n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4\",\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            messages=prompt\n",
    "        )\n",
    "    \n",
    "        annotation = response['choices'][0]['message']['content']\n",
    "        print(annotation)\n",
    "\n",
    "        filename_cot_debug = os.path.join(destination_directory, f'{example_index:03d}_cot_debug.txt') # I'm paying for the tokens, I damn well want to see them\n",
    "        try:\n",
    "            annotation_filtered = re.search('Roleplay:(.*)', annotation, re.DOTALL).group(1)\n",
    "\n",
    "            # Write the scenario to the file\n",
    "            with open(filename_cot_debug, 'w') as f_1:\n",
    "                f_1.write(annotation)\n",
    "\n",
    "            # Assume \"Scenario:\\n\" is followed by the actual scenario\n",
    "\n",
    "            # Create a filename based on the example index\n",
    "            filename = os.path.join(destination_directory, f'{example_index:03d}.txt')\n",
    "\n",
    "            # Write the scenario to the file\n",
    "            with open(filename, 'w') as f_2:\n",
    "                f_2.write(annotation_filtered)\n",
    "        except:\n",
    "            print(\"ERROR in regex, GPT probably screwed up\")\n",
    "    else:\n",
    "        print(f\"Skipping {example_index:03d} because it already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not annotated_dataset_has_been_manually_edited:\n",
    "    \n",
    "    # Create annotated training examples (same # of them as training examples and scenarios)\n",
    "    for idx, example in enumerate(training_data_conversations_filtered):\n",
    "        try:\n",
    "            annotate_conversation(example, 'annotated_convs', idx)\n",
    "        except:\n",
    "            pass # prevent timeouts from screwing me\n",
    "\n",
    "    # Create annotated training examples (same # of them as training examples and scenarios)\n",
    "    for idx, example in enumerate(training_data_conversations_filtered):\n",
    "        try:\n",
    "            annotate_conversation(example, 'annotated_convs', idx)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(scenarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that all annotated files exist\n",
    "\n",
    "for i in range(0,466): # you will want to modify the end value here to make it fit your dataset\n",
    "    if not os.path.exists(f\"./annotated_convs/{i:03d}.txt\"):\n",
    "        print(\"Problem in \", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a different read function modified for annotated filenames:\n",
    "def read_all_dialogues_annotated(directory_path):\n",
    "    # List to store all dialogues (each dialogue is a list of tuples)\n",
    "    all_dialogues = []\n",
    "    \n",
    "    # Get list of all filenames in the directory\n",
    "    filenames = [f for f in os.listdir(directory_path) if not f.endswith('_cot_debug.txt')]\n",
    "    \n",
    "    # Sort filenames by their numerical index\n",
    "    filenames.sort(key=lambda x: int(x.split('.')[0]))\n",
    "    \n",
    "    for filename in filenames:\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        dialogue = read_dialogue(file_path)\n",
    "        all_dialogues.append(dialogue)\n",
    "    \n",
    "    return all_dialogues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unspoken_lines_in_annotated = 0\n",
    "\n",
    "def delete_all_unspoken(tlist,index=9999):\n",
    "    \"\"\"Filters out lines by UNSPOKEN\"\"\"\n",
    "    corrected_tlist = []\n",
    "    global unspoken_lines_in_annotated\n",
    "    for speaker, line in tlist:\n",
    "        if speaker == \"UNSPOKEN\":\n",
    "            unspoken_lines_in_annotated += 1\n",
    "            continue\n",
    "        else:\n",
    "            corrected_line = line\n",
    "        corrected_tlist.append((speaker, corrected_line))\n",
    "    return corrected_tlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "lines_with_unspoken_issues = 0\n",
    "\n",
    "def actionize_spoken_unspoken_lines(tlist, index=9999):\n",
    "    global lines_with_unspoken_issues\n",
    "\n",
    "    # Extract all the UNSPOKEN fragments from the original_conversation\n",
    "    original_conversation = training_data_conversations_filtered[index][-1]\n",
    "    unspoken_fragments = [line for speaker, line in original_conversation if speaker == \"UNSPOKEN\"]\n",
    "    \n",
    "    corrected_tlist = []\n",
    "    for speaker, line in tlist:\n",
    "        corrected_line = line\n",
    "\n",
    "        # For each Okabe line, check if it contains an UNSPOKEN fragment.\n",
    "        if speaker == \"Okabe\":\n",
    "            for fragment in unspoken_fragments:\n",
    "                # Updated regex pattern\n",
    "                pattern = r'(\\*\\s?.+?\\s?\\*)?\\s?\"' + re.escape(fragment) + r'\"\\s?(\\*\\s?.+?\\s?\\*)?'\n",
    "                \n",
    "                def replace_action(match):\n",
    "                    # Extract matched groups\n",
    "                    pre_action = match.group(1) if match.group(1) else ''\n",
    "                    post_action = match.group(2) if match.group(2) else ''\n",
    "                    # Construct replacement\n",
    "                    return '*' + pre_action.strip('*').strip() + ' ' + fragment + ' ' + post_action.strip('*').strip() + '*'\n",
    "\n",
    "                if re.search(pattern, corrected_line):\n",
    "                    lines_with_unspoken_issues += 1\n",
    "                    corrected_line = re.sub(pattern, replace_action, corrected_line)\n",
    "                    corrected_line = corrected_line.replace(\"  \", \" \").replace(\"**\", \"\").strip()  # Cleaning up\n",
    "                    print(\"made a sub at \" + str(index) + \" with line \" + corrected_line)\n",
    "                    \n",
    "            corrected_tlist.append((speaker, corrected_line))\n",
    "        else:\n",
    "            corrected_tlist.append((speaker, line))\n",
    "        \n",
    "    return corrected_tlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "made a sub at 1 with line *I let out a sigh, the sound echoing my exasperation. Cease your foolish laughter! Okabe Rintaro may be my real name, but I have rejected it, for it is stupid. And so I also hate the derivative Okarin. Come on, it sounds like that elf boy’s blue pipe thing. *\n",
      "made a sub at 1 with line *I rub my temples, feeling a headache coming on. In one ear and out the other. She’s been calling me that for five years now, so maybe it’s time to give up. *\n",
      "made a sub at 5 with line *My mind races, trying to recall any encounter with her. I shake my head, dismissing her claim. Nonsense. This is the first time we’ve met. I was with Mayuri and that Upa toy fifteen minutes ago. *\n",
      "made a sub at 5 with line *Her words hit me like a gut punch. I grit my teeth, my hands clenched into fists at my sides. Is this a trap? It does seem like one of the Organization’s dirty tricks. But would this girl do something that underhanded? *\n",
      "made a sub at 5 with line *My heart skips a beat. Her sincere words unsettle me, making me question my own beliefs. She seems sincere. That makes her even more suspicious. That’s right, don’t let her beauty fool you! She’s a cold, calculating secret agent. If I show the slightest vulnerability, I’m done for! *\n",
      "made a sub at 5 with line *I bite my lower lip, my mind racing with thoughts. Well then, what do I do now? My mission was to attend the conference and evaluate Doctor Nakabachi’s research. Now that I know he’s a fraud, there’s no real point in going back. I guess I’ll just go home. But wait. Aren’t I forgetting something important? Let’s see now... what is it? *\n",
      "made a sub at 6 with line *A heavy sigh escapes my lips as the realization hits me. Looks like I’ll have to go back to the assembly hall. But things will get messy if I bump heads with Makise Kurisu again. *\n",
      "made a sub at 6 with line *I start pacing, my mind racing with possibilities. Leaving without Mayuri isn’t an option. Call me overprotective, but she’s like a little sister to me, and there’s a very real danger that she might wander off somewhere the moment I let her out of my sight. Mayuri has always been like that. I never know if she’ll be there when I turn to look. ...In a sense, that’s why I became Hououin Kyouma. *\n",
      "made a sub at 6 with line *My heart sinks as I climb back up to the 8th floor, the weight of the situation pressing down on me. The thought of climbing back up to the 8th floor is depressing, but I have no choice. When I get back to the assembly hall, Doctor Nakabachi’s conference has just finished. Nobody is on stage, and the phony inventor has already left. The 20 or so members of the audience are starting to pack up. I soon find Mayuri. She’s in the corner, looking lost. Well, at least she wasn’t kidnapped. Even better, I don’t see Makise Kurisu anywhere. *\n",
      "made a sub at 6 with line *A sigh escapes my lips. I see, so she was looking for it. Not like it really matters. I wave my hand dismissively.* \"Forget about it. You can always get another one.\"\n",
      "made a sub at 6 with line *I laugh again, the hunt for the Metal Upa proving to be a welcome distraction. Thus begins our search for the Metal Upa. *\n",
      "made a sub at 7 with line *I blink in surprise, my eyebrows shooting up in disbelief. A chuckle escapes my lips before I can stop it. Woah, wasn’t expecting that from Mayuri. *\n",
      "made a sub at 7 with line *My body jerks in surprise, a chill running down my spine as I scan the area.* \"!?\" *I question out loud, the confusion apparent in my tone. Wh-what was that? *\n",
      "made a sub at 11 with line *As I watch my friend Daru, his eyes glued to the screen, his fingers flying over the keyboard, I can't help but marvel at his dedication. This fat, bespectacled guy is my brother-in-arms and right-hand man, Hashida Itaru. Nickname: Daru. He’s a hardcore otaku. You can always find him in front of the computer, playing games and watching anime. He has 2D wives on whom he cheats with 3D maids. I don’t agree with his preferences, but to him, anything’s fine as long as it’s moe. He’s the reliable and skilled partner who brings my ideas to fruition. Despite his insistence that software is his forte, he shows remarkable aptitude with hardware as well. *\n",
      "made a sub at 11 with line *I turn my attention to Mayuri, my heart aching at the sight of her nursing her finger. Over here, nursing a pricked finger, we have Shiina Mayuri. A 16-year-old high school student, if you can believe it. I’ve known her since we were both small. She’s also an otaku. Nowhere near Daru’s level, though. This ditzy girl is in charge of the lab’s official Costume Division (for Women), and today she’s working on costumes at her usual leisurely pace. Why does the Future Gadget Laboratory need costumes (for women)? It doesn’t. The truth is that Mayuri is completely useless. Still, there’s no way I would ever kick her out. After all, she was the first one to join the Future Gadget Laboratory. I still remember the day Mayuri first came to the lab. It was spring. She said to me: *\n",
      "made a sub at 11 with line *The memory of her words brings a rare smile to my face. I nod at her, my heart filled with gratitude. Well, that certainly was cryptic. But her offer was my salvation. For she was the first to join me on my magnificent quest. She saved me from a solitary life on the run from the Organization. I will never forget her kindness. Mayuri doesn’t have to be useful. Her being here is enough. *\n",
      "made a sub at 11 with line *I sigh, the frustration welling up within me. The human-faced alpaca inside the monitor was completely unresponsive. So unresponsive you’d think the game was bugged. Whatever, I give up. Never again will I play this boring game. I curse his name and smack the TV. As soon as I do--* \"Damn antisocial alpaca!\"\n",
      "made a sub at 13 with line *I cock my head, a puzzled frown creasing my face. A huge ’kaplow’... It certainly did make a sound. But I don’t think it was kaplow! I’d say it was more like Zzzzzznnnmmm. I mimic the sound, my hands gesturing in the air to illustrate the noise.* \"Did that satellite fall out of the sky?\"\n",
      "made a sub at 20 with line *Relief floods me as the event staff retreat. Thanks to her proposal, the event staff refrain from escorting me out. She sounds a little pissed, but let’s not mind that. *\n",
      "made a sub at 20 with line *I raise an eyebrow, intrigued despite myself. Hmm... what are the major theories of time travel? I have heard about the cosmic string theory, at least. *\n",
      "made a sub at 20 with line *I nod, impressed despite myself. Hmm... not bad. Perhaps Makise Kurisu is a worthy rival after all. *\n",
      "made a sub at 20 with line *I frown, trying to understand what she means. What does that mean? *\n",
      "made a sub at 21 with line *I squint my eyes, studying Kurisu's features. She seems slightly on edge. Was it just the anticipation of her presentation, or something more? Was it just me, or did Kurisu look a little nervous just now? *\n",
      "made a sub at 21 with line *I raise an eyebrow at Kurisu's explanation. Cosmic strings? A crevice to another universe? These theories, were they really plausible? A string-shaped crevice? That must be how they enter our universe. But do cosmic strings really exist? *\n",
      "made a sub at 21 with line *I glance around, taking in the amused expressions on the audience's faces. Kurisu had managed to turn this complex lecture into something entertaining. This earns a few chuckles from the audience. *\n",
      "made a sub at 21 with line *I blink, caught off guard by Kurisu's direct challenge. Why was she singling me out? Like that’s even possible. And why the hell is she addressing me? I wasn’t even the one who jeered this time. *\n",
      "made a sub at 21 with line *I grit my teeth, feeling the weight of her question. I didn't want to engage, but it seemed I had no choice. No, don’t ask me! I’m trying to hold back here. Since I’ve been challenged, though, I can’t leave the question unanswered. *\n",
      "made a sub at 22 with line *I frown, trying to piece together the puzzle of her words. Uh... how? *\n",
      "made a sub at 22 with line *I lean back, my mind whirling with the sheer impossibility of it all. So, implementation of either one would require a ridiculous amount of effort. *\n",
      "made a sub at 22 with line *I blink, taken aback. What!? Is that true? *\n",
      "made a sub at 22 with line *I grit my teeth, my cheeks burning. Ah! She’s laughing at my reaction! That little... Gah, how mortifying... *\n",
      "made a sub at 23 with line *Listening intently, I find myself musing aloud. Oh, that thing where you kill your own ancestors before you were born? *\n",
      "made a sub at 23 with line *I furrow my brows, deep in thought. Really? It doesn’t seem that dangerous. *\n",
      "made a sub at 25 with line *I shake my head, a small smile playing on my lips as I gaze at Luka's innocent face. Such a lovely smile. But he’s a guy. *\n",
      "made a sub at 25 with line *I chuckle, crossing my arms over my chest. Geez. Though we do have a master-disciple relationship. I, Hououin Kyouma, have gone to great lengths to brainwash -- er, I mean teach -- Lukako about the evil conspiracies that rule the world, and how to resist them. That stuff about Demon Sword Samidare is part of that training. Looks aside, Lukako is very obedient and hardworking. Plus, he’s always eager to learn new things. A master couldn’t ask for a better disciple. Though he does have the weaknesses of not catching on too quickly and being too shy. *\n",
      "made a sub at 25 with line *I glance at Mayuri, my gaze lingering on her hopeful expression before turning back to Luka. Mayuri’s hobby is making costumes. She’s made at least thirty so far, but it’s rare for her to wear one herself. Instead, she seems to get her kicks from seeing other people wear them. And it looks like she’s chosen Lukako as her next target. Naturally, the costume Mayuri is currently raving about is for a female character. Normally, I would understand why a man wouldn’t want to dress like a girl, but come on. Lukako has no problem wearing miko robes. Why should cosplay be any different? But whatever. I have business to take care of. *\n",
      "made a sub at 25 with line *I take a deep breath, glancing around the shrine. That’s why I came here instead of Kanda Shrine. *\n",
      "made a sub at 32 with line *I groan, running a hand through my hair. Playing along with her fantasies is exhausting. Ugh... she’s not letting it go. It’ll take 30 minutes if I play along with her. *\n",
      "made a sub at 32 with line *I sigh, exasperated. Since when do you have a brother!? And what the hell’s this Spirit Conference anyway? Faris looks at me with actual tears in her eyes. I falter, even though I know it’s just one of her cutesy acts. Whenever I talk with her, I run out of comebacks, which is really unusual for me. And then she takes the initiative, leaving me with nothing to do but listen to her fantasies. I mean, come on, you can only take it so far. There’s a very clear difference between her stories and mine. As anyone can see, I speak nothing but the truth, while Faris has only delusions and a made-up backstory! I always have to play along. That’s why I feel like I can never best her. *\n",
      "made a sub at 32 with line *I groan, realizing the conversation is spiraling out of control. Great, now look who’s joined in. It’s just going to get worse from here. I have to end this conversation now! *\n",
      "made a sub at 38 with line *I scrutinize the ancient PC, finding it hard to believe that such a relic could still be operational. I mean, it’s a 20-year-old machine with specs lower than my cellphone. *\n",
      "made a sub at 38 with line *I roll my eyes, muttering under my breath. Selfish bastard. Besides, we made the PhoneWave (name subject to change) together. It’s our crazy machine. *\n",
      "made a sub at 38 with line *I furrow my brow, plagued by the mystery of the gelified banana. Why would a banana gelify? What kind of science are we dealing with here? *\n",
      "made a sub at 42 with line *I clench my fists, determination setting in. I must clear my name, or I’ll be labeled as a perv forever! *\n",
      "made a sub at 42 with line *I stare at her outstretched hand, my mind racing. She holds out her hand. What is she trying to do? Shoot lightning from her fingertips!? *\n",
      "made a sub at 42 with line *I nervously glance at her hand, then back up to her face. Shake hands? This girl genius is asking for a handshake? We only met yesterday, and just moments ago she was on the verge of calling the cops. *\n",
      "made a sub at 42 with line *I deflate a little, but try to keep my composure. Damn. She’s completely cold. Her tone gets scary sometimes, too. *\n",
      "made a sub at 42 with line *I chuckle to myself, finding amusement in my own joke. Perhaps that’s too much to expect from a killing machine. *\n",
      "made a sub at 44 with line *I shake my head, amused. ‘Christina’ sounds like the name of a Hollywood film star. It definitely has more flavor than her real name. I lean in, my voice dropping to a conspiratorial whisper.* \"If you wish to learn the secrets of this microwave, then you must meet my conditions.\"\n",
      "made a sub at 47 with line *A memory surfaces, connecting dots in my mind. That’s right. I went to see Doctor Nakabachi’s conference yesterday. Come to think of it, he stole his time travel theory from John Titor. Maybe the current John Titor is actually Nakabachi. *\n",
      "made a sub at 47 with line *My mind stumbles, the memory doesn't match up. ...No, I don’t remember that. After all, Nakabachi’s presentation wasn’t canceled, the way I remember it. I still don’t understand why my memories seem to disagree with everyone else’s. *\n",
      "made a sub at 49 with line *I glance at Mayuri, a sense of dread creeping over me. I knew this would happen eventually. It sounds like Mayuri has found the results of our latest experiment. *\n",
      "made a sub at 59 with line *I feel a jolt of realization, my mind racing back to the past. Now I remember. John Titor said the same thing in 2000. And right after that, an IBN engineer officially admitted to that function’s existence. My fingers twitch at the memory, the pieces of the puzzle starting to fall into place.*\n",
      "made a sub at 59 with line *I furrow my brows, deep in thought, watching Suzuha play with the pin. The reason Titor traveled to 1975 to obtain an IBN 5100 was because he needed that function. Maybe Moeka wants to use it too. Or maybe not. Shining Finger doesn’t seem like the type who’d know about that sort of function. I mutter, my mind spinning with possibilities.*\n",
      "made a sub at 68 with line *I sigh in frustration, running a hand through my hair. Come on! I even said I’d show you a living hell! *\n",
      "made a sub at 68 with line *I watch as Suzuha's temper flares, a hint of amusement on my face. Suzuha’s actually mad now. *\n",
      "made a sub at 95 with line *I glance at the path leading to the lab, calculating the distance in my head. Fortunately, the lab is less than a 15 minute walk from here. *\n",
      "made a sub at 96 with line *I pat my pockets, realizing my phone was on silent. My phone? That reminds me. Before I went to Yanabayashi Shrine, I got a call from an unknown number. So that was her? *\n",
      "made a sub at 106 with line *I lean back in my chair, my eyes lost in the maze of conspiracy theories swirling in my mind. So maybe that’s why the IBN 5100 was central to SERN’s operations. The years match, after all. It can’t be something as stupidly simple as that. There has to be a worldwide conspiracy involved. Maybe IBN hid their proprietary programming language in the IBN 5100 for the sole purpose of its use in SERN’s Z Program. IBN and SERN are co-conspirators. And both of them are being manipulated from the shadows by an even larger organization. Yeah, that’s way more interesting. *\n",
      "made a sub at 106 with line *I feel my heart stop for a moment, the words echoing in my mind. Time-space displacement experiments. *\n",
      "made a sub at 113 with line *I shake my head, a sense of vertigo washing over me. I can’t even imagine what that’s like. *\n",
      "made a sub at 113 with line *I remember Kurisu's earlier words, my mind racing. The negation of the theory of relativity and the principle of causality means serious paradoxes can occur. Didn’t Kurisu say that earlier? *\n",
      "made a sub at 113 with line *I recall John Titor's words, my mind connecting the dots. John Titor said the same thing. So Titor’s time machine is using SERN’s technology. But Titor’s time machine was compact, small enough to fit into a car. The LHC is 27 kilometers long, but they managed to get it down to travel size in just 24 years. *\n",
      "made a sub at 129 with line *I soften, my tone more understanding.* \"...I am not without sympathy for your plight. I formed a contract with the IBN 5100 for my own goals. After I achieve those goals, you can negotiate with the original owner to form a contract of your own.\" *I take a deep breath, steeling myself for the battle ahead. When I return the IBN 5100 to Yanabayashi Shrine, Ragnarok will be over, and the fate of the world will have already been decided. *\n",
      "made a sub at 129 with line *I sigh, rolling my eyes. Geez, I had some good angst going there. She’s just oblivious to the mood. I shake my head, a wry smile on my lips.* \"The IBN 5100 was at Yanabayashi Shrine.\"\n",
      "made a sub at 129 with line *I watch as Daru greets Moeka, a hint of amusement in my eyes. Even though Daru bowed his head, Moeka doesn’t so much as look at him. She’s now looking down at her phone -- not that she ever really looked away. Daru turns red. *\n",
      "made a sub at 152 with line *I raise an eyebrow, intrigued by her response. A policy? *\n",
      "made a sub at 161 with line *I grit my teeth in annoyance, muttering to myself, Gh, dammit. You’re just an assistant. Don’t boss us around! *\n",
      "made a sub at 165 with line *I nod, a wistful smile on my face. Of course. That’s the most common of common knowledge. *\n",
      "made a sub at 178 with line *I pinch the bridge of my nose, feeling a headache coming on. And he’s broken! Women are scary... *\n",
      "made a sub at 178 with line *I roll my eyes, my arms crossed in exasperation. Dumbass. What’s with that grin? *\n",
      "made a sub at 181 with line *I shake my head, the corner of my mouth lifting in a wry smile at Mayuri's innocent misunderstanding. Sigh, kids these days. *\n",
      "made a sub at 181 with line *I chuckle softly, relieved that she understood my jest. Seems like she understood the rest of what I said. It was just a joke, anyway. *\n",
      "made a sub at 181 with line *I find myself pondering, a thought crossing my mind. Come to think of it, Mayuri has never talked about her future. *\n",
      "made a sub at 181 with line *I raise an eyebrow, taken aback by her sudden shift in topic. That’s a sudden change in topic. And for some reason, she’s puffing her chest out in pride. *\n",
      "made a sub at 181 with line *I let out a soft sigh, my gaze fond as I watch her. Sometimes Mayuri throws me off my game. But if that’s her reason for staying at the lab, then I’m happy. *\n",
      "made a sub at 189 with line *I rub my chin thoughtfully, mulling over the new information. So that’s it... At any rate, Faris has confirmed that the IBN 5100 was at Yanabayashi Shrine. So did the IBN 5100 disappear from the lab after I retrieved it? No, Kurisu and the others lost their memories of me bringing it back to the lab. So I’m considering two possibilities: One. I went to the shrine, but didn’t acquire the IBN 5100. It’s still at the shrine. Two. Before I went to the shrine, someone moved the IBN 5100 somewhere else. Looks like I’ll have to go to the shrine after all. *\n",
      "made a sub at 189 with line *I sigh, realizing the daunting task at hand. We only need to find one. It doesn’t matter if it’s the one I found at the shrine. *\n",
      "made a sub at 191 with line *I roll my eyes at his dramatics, my arms crossed in front of my chest. Quit grumbling. You just can’t handle the truth! I turn to Mayuri, my gaze softening.* \"Well, Mayuri? Don’t you know?\"\n",
      "made a sub at 193 with line *I reel back, both infuriated and entranced by the enchanting catgirl before me. Damn you, catgirl! How dare you make a fool of me!? *\n",
      "made a sub at 193 with line *I smirk, expecting Faris to cower in fear. Instead, her eyes sparkle with intrigue. That’s my line. I wanted to threaten her, not seduce her. Is Faris a masochist!? *\n",
      "made a sub at 196 with line *I frown, my fingers moving swiftly to redial Kurisu's number. Again! *\n",
      "made a sub at 196 with line *I notice Faris's hesitation, and I feel a pang of curiosity. Hm? What happened to her usual confidence? *\n",
      "made a sub at 215 with line *My heart pounds in my chest, each beat echoing in the silent void that surrounds me. This is a dream, right? *\n",
      "made a sub at 215 with line *I swallow hard, my throat dry as sand. This is a dream... right, Mayuri? *\n",
      "made a sub at 217 with line *I feel a chill creep up my spine as I think about the implications. The harder something is to obtain, the stronger the desire for it becomes. That’s how people are. And that’s exactly how I feel now. In the depths of SERN, completely isolated from the outside, lies a database coded with an IBN 5100. What secrets are sleeping there? Could it contain the data from SERN’s time machine research? Could there be proof that the Committee of 300 exists? The desire to know grows stronger by the day. It’s not just about plunging the world into chaos anymore. We need the power to oppose SERN’s evil ambitions. And then there’s that threatening email to consider. Daru is confident that SERN won’t find us, but I can’t afford to take that for granted. After all, we’re up against the brightest minds in the world, the scientists who invented the world wide web. And they’re backed by a secret organization more powerful than any nation. We’re way out of our league here. They’d have no trouble at all crushing our puny lab if they desired. That’s why we need a trump card to hold against them. But without an IBN 5100, we can’t move forward. I’m getting restless. *\n",
      "made a sub at 219 with line *I lean forward, my eyebrows furrowed in confusion. Figured what out? *\n",
      "Added a space at index  291\n",
      "Added a space at index  291\n",
      "2 685 3567 9 87\n",
      "[('Kurisu', '*I tilt my head to the side, examining the man in front of me, my eyebrows furrowed in confusion.* \"Huh? Your phone\\'s off. ...Who were you talking to?\"'), ('Okabe', '*My eyes dart away from her piercing gaze, my heart pounding in my chest.* \"Y-your techniques don\\'t work on me, but I\\'ll tell you anyway. That\\'s no ordinary phone. It\\'s designed to deactivate the moment it leaves my hand. Muhahaha!\" *I quickly retrieve my phone, wiping the cold sweat off my forehead with the back of my hand. My laughter echoes in the hallway, a desperate attempt to mask my fear.*'), ('Kurisu', '*I raise an eyebrow, crossing my arms over my chest.* \"...So you talk to yourself.\"'), ('Okabe', '*I wince at her words, feeling my pride being trampled under her straightforwardness.* \"Guh!\" *I try to formulate a witty comeback, but my mind is racing with paranoia. I take a step back, trying to put some distance between us.*'), ('Kurisu', '*I step forward, matching his retreat.* \"What were you trying to tell me earlier?\"'), ('Okabe', '*Her words hit me like a sledgehammer. My eyes widen in surprise, my mind scrambling to make sense of her question.* \"What are you talking about?\"'), ('Kurisu', '*I squint at him, trying to recall our earlier encounter.* \"About fifteen minutes ago. Before the conference started.\"'), ('Okabe', \"*My mind races, trying to recall any encounter with her. I shake my head, dismissing her claim. Nonsense. This is the first time we've met. I was with Mayuri and that Upa toy fifteen minutes ago. *\"), ('Kurisu', '*I bite my lower lip, my eyes reflecting a deep concern.* \"You were trying to tell me something, right? You looked really upset.\"'), ('Okabe', \"*Her words hit me like a gut punch. I grit my teeth, my hands clenched into fists at my sides. Is this a trap? It does seem like one of the Organization's dirty tricks. But would this girl do something that underhanded? *\"), ('Kurisu', '*I take a deep breath, my gaze unwavering.* \"You looked like you were going to start crying any second. Why? Have we met before?\"'), ('Okabe', \"*My heart skips a beat. Her sincere words unsettle me, making me question my own beliefs. She seems sincere. That makes her even more suspicious. That's right, don't let her beauty fool you! She's a cold, calculating secret agent. If I show the slightest vulnerability, I'm done for! *\"), ('Kurisu', '*I frown, my curiosity piqued.* \"And how do you know my name?\"'), ('Okabe', '*I flash her a smirk, mustering up my bravado.* \"My knowledge has no limits.\" *I point a finger at her, my voice echoing down the hallway.* \"Genius girl, our next meeting shall be as enemies!\"'), ('Kurisu', '*I blink at him, taken aback by his sudden declaration.* \"Huh?\"'), ('Okabe', '*I spin on my heel, my heart pounding in my chest as I dash down the stairs.* \"Farewell! Muhahaha!\" *I take a moment to catch my breath, my hands on my knees as I pant heavily.* \"Damn the Organization! They must be serious if they\\'re sending in agents like her!\" *I look over my shoulder, ensuring I wasn\\'t being followed.* *I sigh, rubbing my temples, trying to make sense of the situation.* \"But I can\\'t let them capture me yet.\" *I bite my lower lip, my mind racing with thoughts. Well then, what do I do now? My mission was to attend the conference and evaluate Doctor Nakabachi\\'s research. Now that I know he\\'s a fraud, there\\'s no real point in going back. I guess I\\'ll just go home. But wait. Aren\\'t I forgetting something important? Let\\'s see now... what is it? * *I slap my forehead, realization washing over me.* \"...Damn. I left Mayuri behind.\"')]\n"
     ]
    }
   ],
   "source": [
    "# Get annotated conversations back into notebook data from files\n",
    "\n",
    "# # read off every annotated conversation, and make a list of them that lines up with the training data\n",
    "annotated_conversations = read_all_dialogues_annotated(\"./annotated_convs\")\n",
    "\n",
    "# Reset global data analysis variables\n",
    "lines_with_bad_quotes = 0\n",
    "lines_merged = 0\n",
    "lines_with_space_issues = 0\n",
    "\n",
    "processed_annotated_conversations = list(map(call_multiple_processors(delete_all_unspoken,actionize_spoken_unspoken_lines,remove_only_ellipsis_lines,merge_consecutive_lines,add_space_after_punctuation,replace_odd_quote,), enumerate(annotated_conversations)))\n",
    "\n",
    "print(lines_with_space_issues,lines_merged,lines_with_bad_quotes,unspoken_lines_in_annotated,lines_with_unspoken_issues)\n",
    "print(processed_annotated_conversations[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_anchors(text):\n",
    "    # Split the text by newline to get individual lines\n",
    "    lines = text.split('\\n')\n",
    "    \n",
    "    # Pattern for extracting the speaker, line number, and content\n",
    "    pattern = r\"(\\w+) \\((\\d+)\\): (.+)\"\n",
    "    \n",
    "    # List to store the results\n",
    "    result = []\n",
    "    \n",
    "    for line in lines:\n",
    "        match = re.match(pattern, line)\n",
    "        if match:\n",
    "            # Extract the speaker, line number, and content from the matched groups\n",
    "            speaker = match.group(1)\n",
    "            line_number = int(match.group(2))  # Convert line number to integer\n",
    "            content = match.group(3)\n",
    "            \n",
    "            # Append the values to the result list\n",
    "            result.append((speaker, line_number, content))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anchor Annotate\n",
    "\n",
    "# Steps: same as before but this time we format the conv with line numbers\n",
    "# and replace the lines whose numbers match the newly-generated anchors\n",
    "\n",
    "# For each thing in processed_annotated_conversations, call this on it\n",
    "def create_anchors(training_data_example, destination_directory, example_index):\n",
    "    anchor_prompt = \"\"\"You are an expert creative writing AI with deep understanding of internet roleplay formats and masterful writing ability. \n",
    "\n",
    "You will be given a modified scene from the Visual Novel Steins;Gate. Each line spoken is numbered. Some lines in this scene are very important and have a lot of narrative/emotional weight. Your goal is to pick one or two of the numbered lines, based on relevance and content, and rewrite the *actions* of those lines to make them stunning anchors of the entire scene. This will be accomplished through a mixture of embellishment, creativity, and expansion of the original line. \n",
    "\n",
    "All lines should be adapted to be in the first person, e.g., *I do X*.\n",
    "\n",
    "Here's an example. Consider the line:\n",
    "\n",
    "\\\"\\\"\\\"\n",
    "Kurisu: \"Sigh... You still haven't made up your mind? You like Mayuri, don't you?\" *She looks away, seemingly frustrated but also concerned.*\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "The context behind that line is that Kurisu is asking Okabe whose life he is going to save — hers or Mayuri's — near the end of the Visual Novel. It's in the middle of a very tense and emotional scene. You could enhance it to become: \n",
    "\n",
    "\\\"\\\"\\\"\n",
    "Kurisu: *I hesitate, my fingers tracing a pattern on the cold concrete beneath me, as if it could somehow help me find the right words. My breath catches, and I feel a sting in my eyes. It's a vulnerability I seldom let myself feel.* \"Sigh... Have you still not made up your mind?\" *I search his face, looking for an answer, my voice trembling but firm.* \"You like Mayuri, don't you?\" *I muster every ounce of courage to ask the question, needing clarity in this whirlwind of emotions.*\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "Make sure the *thoughts*, *actions*, and word choice of each anchor line match the personalities of the character speaking/doing the line.\n",
    "\n",
    "Maintain the Character (number): line format of the line(s) you change. Ensure the enhanced line doesn't break the scene's continuity.\"\"\"\n",
    "    full_conversation = training_data_example[-1]\n",
    "    context = '\\n\\n'.join([f'({i + 1}) {l[0]}: {l[1]}' for i, l in enumerate(training_data_example)])\n",
    "\n",
    "    scenario = scenarios[example_index]\n",
    "\n",
    "    if not os.path.exists(os.path.join(destination_directory, f'{example_index:03d}.txt')):\n",
    "        prompt = [{\n",
    "            \"role\" : \"system\", \"content\" : anchor_prompt\n",
    "            },\n",
    "                    {\n",
    "            \"role\" : \"user\",\n",
    "            \"content\" : f\"\"\"Scenario/setting: \\\"\\\"\\\"{scenario}\\\"\\\"\\\"\n",
    "\n",
    "Text to add some good anchors to:\n",
    "\\\"\\\"\\\"\n",
    "{context.replace(\"Rintaro:\", \"Okabe:\").strip()}\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "## Be sure to remember:\n",
    "Recall that your task is to find 4 important lines that can be lengthened and embellished significantly, so as to give greater impact to important parts of a scene through absolutely stellar prose that makes up for the lack of a visual element in the plain text. The writing should be powerful and nuanced, conveying small details that reveal characters' motivations, personalities, and thoughts, without overtly stating them — it should be deep and poetic at once. About 4–5 sentences long (60-70 words per enhanced line). However, for the sake of ensuring continuity with the original scene, don't change the words that are spoken.\n",
    "1. Write using a variety of words and immense stylistic flair appropriate to the scene. Be creative and prioritize making the new lines compelling instead of 100% accurate to the original. Alternate short, snappy responses with long and detailed prose to give the text a good rhythm.\n",
    "2. BE SURE to write the CORRECT speaker for any given line, I have seen a few cases where you accidentally switch who is saying a line and that messes up the whole scene. Also, do not break the important roleplay rule whereby characters should not act on behalf of other characters: Okabe should not think or take *actions* during one of Kurisu's lines, for instance. No one but the character whose line it is should speak on that line. And of course don't change the words that are \"spoken\" in your enhanced lines.\n",
    "3. In your planning stage, explicitly mention the archetypes/personalities of each of the characters involved, and take brief notes on what word choices/writing styles you'll write their *actions and thoughts* in, considering that information.\n",
    "4. IMPORTANT: the writing should be powerful and nuanced, conveying small details that reveal characters' motivations, personalities, and thoughts, often without overtly stating them — it should be deep and poetic at once, and ought to make up for the lack of a visual element in plain text. Write powerfully, but not pretentiously.\n",
    "\n",
    "Before you begin, you should plan out and brainstorm your approach. In your planning stage, explicitly identify lines you are going to radically enhance with extra-long actions to serve as the \"anchors\" of the scene. These anchors, after you add your extensive, prose-like *actions* to them, should end up being at least 60 WORDS long, and very compelling. Mention in your plans which 4 lines will be anchors, AND what thematic direction you'll take them in.\n",
    "\n",
    "Don't rewrite the entire text: just add your new high-quality lines, with the correct line number. Write out the original lines that you're changing in your brainstorming step so that you can better remember what their contents are and can be sure to not forget any \"dialogue\".\n",
    "\"\"\"\n",
    "            }]\n",
    "        if example_index == 0: # make sure not going catastrophically wrong\n",
    "            print(\"------\".join([d[\"content\"] for d in prompt]))\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4\",\n",
    "            temperature=0.7,\n",
    "            n=1,\n",
    "            top_p=0.9,\n",
    "            messages=prompt\n",
    "        )\n",
    "    \n",
    "        anchors = response['choices'][0]['message']['content']\n",
    "        \n",
    "        filename = os.path.join(destination_directory, f'{example_index:03d}.txt') # process for getting lines from cot file is exact same time complexity as getting from non-cot file. Only going to save one type\n",
    "        with open(filename, 'w') as f_1:\n",
    "                f_1.write(anchors)\n",
    "    else:\n",
    "        print(f\"Skipping {example_index:03d} because it already exists.\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_annotated_conversations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make anchors\n",
    "if not annotated_dataset_has_been_manually_edited:\n",
    "    for idx, annotated_conv in enumerate(processed_annotated_conversations[:35]):\n",
    "        create_anchors(annotated_conv,\"anchors\",idx)\n",
    "        \n",
    "# modify processed examples to have the new anchor lines\n",
    "# happens regardless of whether we're doing this the first time or not\n",
    "for idx, annotated_conv in enumerate(processed_annotated_conversations):\n",
    "    filename = f\"anchors/{idx:03d}.txt\"\n",
    "    with open(filename, \"r\") as f:\n",
    "        newlines = extract_anchors(f.read())\n",
    "        for line in newlines: # modify processed_annotated_conversations in place. I don't have to reread things from files now.\n",
    "            processed_annotated_conversations[idx][line[1]] = (line[0], line[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll do this in the training script, not the data creation script\n",
    "# for annovated_conv in processed_annotated_conversations:\n",
    "#     for idx, line in enumerate(annotated_conv):\n",
    "#         annotated_conv[idx] = (line[0],line[1].replace(\"*\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_annotated_conversations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_annotated_conversations[0] # The modification in-place works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge lines and such again, in case of errors. Watch for output here, there shouldn't be any.\n",
    "processed_annotated_conversations = list(map(call_multiple_processors(remove_only_ellipsis_lines,merge_consecutive_lines,add_space_after_punctuation,replace_odd_quote), enumerate(processed_annotated_conversations)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case this hasn't been run already, due to the flag being set (the number of training examples in the annotated dataset/scenario files may be different than the number generated by the script if the user deleted some manually) we can run it here\n",
    "if annotated_dataset_has_been_manually_edited:\n",
    "        def make_scenario_list_trainingdata():\n",
    "                scenario_list = []\n",
    "                for idx, content in enumerate(processed_annotated_conversations):\n",
    "                        with open(f\"scenarios/{idx:03d}.txt\", \"r\") as f:\n",
    "                                scenario_list.append(f.read())\n",
    "                return scenario_list\n",
    "\n",
    "        scenarios = make_scenario_list(processed_annotated_conversations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(annotated_conversations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whole process text loop again, turn into tuple list\n",
    "# Create training examples (again)\n",
    "training_data_conversations_annotated = list(map(generate_training_examples, processed_annotated_conversations))\n",
    "training_data_conversations_annotated = [[subsublist for subsublist in sublist if len(subsublist) > 1] for sublist in training_data_conversations_annotated]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper that creates JSON object for a training example at a certain index (annotated history, annotated completion, scenario)\n",
    "def create_json_object(annotated_conversation, example_index):\n",
    "    last_speaker, last_line = annotated_conversation[-1]\n",
    "    return { # or something like this\n",
    "        \"history\": '\\n'.join([f'{speaker}: {line}' for speaker, line in annotated_conversation[:-1]]), # Since spoken lines probably don't have newlines, we can safely split at newlines to get the speakers back from the json\n",
    "        \"completion\": f'{last_line}',\n",
    "        \"speaker\": annotated_conversation[-1][0],\n",
    "        \"scenario\": scenarios[example_index],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn annotated conversation into list of json objects for eventual use in the training script\n",
    "\n",
    "final_examples = []\n",
    "for idx, conv in enumerate(training_data_conversations_annotated): # conv is a list of lists of tuples\n",
    "    for ex in conv: # ex is a list of tuples\n",
    "        final_examples.append(create_json_object(ex,idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect\n",
    "final_examples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('final_dataset.json','w') as f:\n",
    "    f.write(json.dumps(final_examples, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('mlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4976e0179d97dd6d59b1329a76e601e17b789c2571b41c8b57f5fd69821c0dd3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
