{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Text (raw) \n",
    "# But the functions will work on the later text, too.\n",
    "import re\n",
    "testval = 0\n",
    "\n",
    "# Step 1: Remove Unwanted Strings\n",
    "# Regex to match unwanted patterns enclosed in []\n",
    "unwanted_pattern = re.compile(r\"\\[color index=\\\".*?\\\"\\]|\\[(?!name|line|%p).*?\\]\")\n",
    "def remove_unwanted_strings(text):\n",
    "    return unwanted_pattern.sub('', text)\n",
    "\n",
    "# Step 2: Parsing the text\n",
    "# I'll update the regular expressions to exclude the delimiters.\n",
    "name_regex = re.compile(r\"\\[name\\](.*?)\\[line\\]\")\n",
    "dialogue_regex = re.compile(r\"\\[line\\](.*?)\\[%p\\]\")\n",
    "monologue_regex = re.compile(r\"^(.*?)(?=\\[%p\\])\")\n",
    "\n",
    "def makecols(str):\n",
    "    global testval\n",
    "    \"\"\"Returns a tuple of (speaker, dialogue) from a single line from the script\"\"\"\n",
    "    name_results = name_regex.search(str)\n",
    "    dialogue_results = dialogue_regex.search(str)\n",
    "    if name_results is None:\n",
    "        monologue_results = monologue_regex.search(str)\n",
    "        return ('UNSPOKEN', monologue_results.group(1) if monologue_results else \"\")\n",
    "    try: \n",
    "        return (name_results.group(1).strip(), dialogue_results.group(1).strip())\n",
    "    except:\n",
    "        print(f\"This is the name_results: {name_results}.\\nAnd this is the dialogue: {dialogue_results}\")\n",
    "        testval += 1\n",
    "        return ('ERROR!', '')\n",
    "\n",
    "def not_empty_monologue(tup):\n",
    "    if (tup[0] == 'UNSPOKEN') and (tup[1] == ''):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# Step 3: Final Processing\n",
    "def process_script(filename):\n",
    "    \"\"\"Returns a list of tuples of (speaker, dialogue) from a script file, filters out empty monologue lines\"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        raw_script = f.read()\n",
    "\n",
    "    # Remove unwanted strings\n",
    "    cleaned_script = remove_unwanted_strings(raw_script)\n",
    "\n",
    "    # Split the cleaned_script into lines and filter out empty lines\n",
    "    lines = [line.strip() for line in cleaned_script.split('\\n') if line.strip()]\n",
    "\n",
    "    # Process each line to make a tuple of (speaker, dialogue)\n",
    "    script_tuples = list(map(makecols, lines))\n",
    "    script_tuples = list(filter(not_empty_monologue, script_tuples))\n",
    "\n",
    "    \n",
    "    return script_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_tuples = process_script('combined_script.txt')\n",
    "print(script_tuples[:20])  # Just printing the first 10 for visualization\n",
    "\n",
    "\n",
    "script = process_script('combined_script.txt')\n",
    "print(testval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('UNSPOKEN',\n",
       " 'There’s no sound from the phone against my right ear. Only silence.')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove_unwanted_strings(\"There’s no sound from the phone against my right ear. Only silence.[%p]\")\n",
    "makecols(\"There’s no sound from the phone against my right ear. Only silence.[%p]\")\n",
    "# monologue_regex.search(\"There’s no sound from the phone against my right ear. Only silence.[%p]\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHARACTER CHOICE #\n",
    "# Change the global values here if you want to change the character dataset being created, and the person the \"user\" is roleplaying as.\n",
    "\n",
    "# The character the user is roleplaying as\n",
    "user_char = \"Rintaro\"\n",
    "\n",
    "# The character the model is going to be trained to be\n",
    "model_char = \"Kurisu\"\n",
    "\n",
    "# NOTE: DOUBLE CHECK THAT THESE ARE RIGHT BEFORE RUNNING THE NOTEBOOK #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Tuple List Processors (before the example generation)\n",
    "def remove_only_ellipsis_lines(tlist):\n",
    "    \"\"\"Remove lines that only contain ellipsis.\"\"\"\n",
    "    return [(speaker, line) for speaker, line in tlist if line.replace('“','').replace('”','') != \"...\"]\n",
    "\n",
    "def merge_consecutive_lines(tlist):\n",
    "    merged_tlist = []\n",
    "    last_speaker = None\n",
    "    for speaker, line in tlist:\n",
    "        line_filtered = line.replace(\"“\",'').replace(\"”\",'')\n",
    "        if not merged_tlist or speaker != last_speaker:\n",
    "            # New speaker or first dialogue, just add it to the list\n",
    "            merged_tlist.append((speaker, line.replace(\"“\",'').replace(\"”\",'')))\n",
    "        else:\n",
    "            # Same speaker as before, concatenate the lines\n",
    "            prev_speaker, prev_line = merged_tlist.pop()\n",
    "            merged_tlist.append((prev_speaker, (prev_line + \" \" + line).replace(\"“\",'').replace(\"”\",'')))\n",
    "        last_speaker = speaker\n",
    "    return merged_tlist # why do this step here? Because I don't want to iterate over the dataset twice, and monologues should count when examples are being generated with the sliding window, so I can't remove them in the usual spot.\n",
    "\n",
    "\n",
    "def add_space_after_punctuation(tlist):\n",
    "    corrected_tlist = []\n",
    "    for speaker, line in tlist:\n",
    "        # Add a space wherever there is a punctuation mark followed by a letter, excluding ellipsis\n",
    "        corrected_line = re.sub(r'([.,!?])(?<!\\.\\.\\.)(\\w)', r'\\1 \\2', line)\n",
    "        corrected_tlist.append((speaker, corrected_line))\n",
    "    return corrected_tlist\n",
    "\n",
    "def replace_odd_quote(tlist):\n",
    "    corrected_tlist = []\n",
    "    for speaker, line in tlist:\n",
    "        corrected_line = line.replace(\"‘\", \"'\").replace(\"’\", \"'\")\n",
    "        corrected_tlist.append((speaker, corrected_line))\n",
    "    return corrected_tlist\n",
    "\n",
    "def call_multiple_processors(tlist, *args):\n",
    "    \"\"\"call all processing functions on the provided tuple list and return the new tuple list\"\"\"\n",
    "    tuple_list = tlist.copy()\n",
    "    for func in args:\n",
    "        tuple_list = func(tuple_list)\n",
    "    return tuple_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the tuple list processors\n",
    "script_tuples_no_ellipsis = remove_only_ellipsis_lines(script_tuples)\n",
    "script_tuples_no_consecutive = merge_consecutive_lines(script_tuples_no_ellipsis)\n",
    "script_tuples_punctuation_fixed = add_space_after_punctuation(script_tuples_no_consecutive)\n",
    "script_tuples_quote_fixed = replace_odd_quote(script_tuples_punctuation_fixed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the tuple list processing functions don't do things that need to be repeated for the reading of the annotated script stuff. They're one-off operations. Thus they do not need to be abstracted further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create conversations from raw text\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm import tqdm # it's not machine learning if there's no progress bar\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Gryphe/MythoMax-L2-13b\")\n",
    "\n",
    "def generate_examples(script, tokenizer, model_char_count_min=1, window_length=10, user_char_count_min=1, max_lines_without_model_char=10):\n",
    "    \"\"\"Extracts useful conversations from the script according to a specific algorithm:\n",
    "\n",
    "    1. A conversation is defined as a sequence of lines where the model_char speaks at least model_char_count_min times and the user_char speaks at least user_char_count_min times.\n",
    "    2. A conversation ends when the model_char has not spoken for max_lines_without_model_char lines.\n",
    "    3. A conversation is saved and a new one started if it is longer than window_length lines.\n",
    "    \n",
    "    \"\"\"\n",
    "    # MAX_TOKENS = 1500  # This produced really really good examples, but they were too large for GPT-4 to annotate while remembering its instructions, so I had to reduce it\n",
    "    MAX_TOKENS = 900\n",
    "\n",
    "    examples = []\n",
    "    sliding_window = []\n",
    "    example = []\n",
    "    model_char_counter = 0\n",
    "    user_char_counter = 0\n",
    "    lines_without_model_char = 0\n",
    "    making_conversation = False\n",
    "\n",
    "    for dialogue in tqdm(script):\n",
    "        speaker, line = dialogue\n",
    "\n",
    "        if len(sliding_window) == window_length:\n",
    "            sliding_window.pop(0)  # Remove first element\n",
    "\n",
    "        sliding_window.append(dialogue)\n",
    "\n",
    "        # Check if there are more than model_char_count_min spoken lines from model_char across sliding_window\n",
    "        model_char_counter = sum(1 for d in sliding_window if d[0] == model_char)\n",
    "        user_char_counter = sum(1 for d in sliding_window if d[0] == user_char)\n",
    "\n",
    "        if speaker == model_char:\n",
    "            lines_without_model_char = 0  # Reset count\n",
    "        else:\n",
    "            lines_without_model_char += 1  # Increment count\n",
    "            \n",
    "        can_start_conversation = model_char_counter >= model_char_count_min and user_char_counter >= user_char_count_min\n",
    "        should_stop_conversation = making_conversation and (len(tokenizer.encode(' '.join([d[1] for d in example]))) > MAX_TOKENS or lines_without_model_char > max_lines_without_model_char)\n",
    "        \n",
    "        if making_conversation:\n",
    "            if should_stop_conversation: # making conversation and should stop\n",
    "                examples.append(example)\n",
    "                example = []\n",
    "                sliding_window = []\n",
    "                model_char_counter = 0\n",
    "                user_char_counter = 0\n",
    "                lines_without_model_char = 0\n",
    "                making_conversation = False\n",
    "            else: # making conversation and should not stop\n",
    "                example.append(dialogue)\n",
    "        elif can_start_conversation: # not making conversation and should start, by appending an example to conversation as well as the entire sliding window\n",
    "            start_appending = False\n",
    "            for d in sliding_window:\n",
    "                speaker, _ = d  # Extract the speaker from the tuple\n",
    "                if not start_appending:\n",
    "                    if speaker in [\"UNSPOKEN\", user_char, model_char]:\n",
    "                        start_appending = True  # Start appending from this point onward\n",
    "                if start_appending:\n",
    "                    example.append(d)\n",
    "            sliding_window = []\n",
    "            making_conversation = True\n",
    "\n",
    "    if example:  # Add last example if it's non-empty\n",
    "        examples.append(example)\n",
    "\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14351/14351 [00:03<00:00, 3857.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "created_examples_script = generate_examples(script_tuples_quote_fixed, tokenizer,)\n",
    "print(len(created_examples_script))\n",
    "# with open(\"script_dump.txt\", \"w\") as f:\n",
    "#     f.write(''.join())\n",
    "# print(created_examples_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('UNSPOKEN',\n",
       "  \"I try to warn her, but Mayuri is no longer there. She's gone. Mayuri disappears like this every so often. And each time she does, I wonder for one terrible second if she really has vanished from the world. I look around and see Mayuri standing at a distance. She's gazing up at the sky through the buildings. ...Here we go again. She's stopped in the middle of the street, so other pedestrians look at her, wondering what she's doing. But she doesn't notice their stares. She slowly reaches out to the sky, as if entranced. And then she freezes in that position. This is one of Mayuri's habits. I call it Stardust Handshake. Mayuri says that she's liked looking at the night sky ever since she was little. Her reason is romantic -- or perhaps childish.\"),\n",
       " ('Mayuri', 'I feel like I can reach the stars.'),\n",
       " ('UNSPOKEN',\n",
       "  \"When I asked her about it one day, she just smiled and gave that answer. At first she only reached out to the night sky, but lately, she's been doing it without regard to the time of day. Like now. Even when she's walking and talking with someone, something inside her just seems to switch on. Honestly, it's a little crazy.\"),\n",
       " ('Rintaro', \"It's too early for stars, Mayuri.\"),\n",
       " ('UNSPOKEN',\n",
       "  'I walk up to Mayuri and call out to her. She slowly lowers her hand with a blank smile on her face.'),\n",
       " ('Mayuri',\n",
       "  'Did you know? Even during the day, the stars are still up there.'),\n",
       " ('Rintaro',\n",
       "  \"Getting philosophical is nice and all, but it's dangerous to stop in the middle of the street.\"),\n",
       " ('Mayuri',\n",
       "  \"Ehehe! That's true. Oh, just now, when I was looking at the stars, I decided to have ramen for lunch today!\"),\n",
       " ('UNSPOKEN',\n",
       "  \"How are ramen and stars even related? Mayuri's mind works in mysterious ways. I know I said I'd search for the IBN 5100, but I have no idea where to start. I spent about an hour in an internet cafe searching for information, but turned up nothing. I buy some mango juice with tapioca from a juice stand inside Yodobashi. I lose myself in thought as I drink it. It's Saturday, so it's starting to get crowded in front of the station. Some maids are distributing leaflets to the people coming out. I know Daru's well-acquainted with retro PCs, but is there anyone else? Oh yeah, Shining Finger was obsessed with the IBN 5100, wasn't she? I'm really reluctant to contact that mail demon, though... But ultimately, my feelings are trivial. Ragnarok hangs in the balance. I don't know Shining Finger's phone number, so I'll just send her an email for the time being. Once I finish drinking my juice, I aimlessly head towards Chuo-dori. And then comes an email. It's from Shining Finger. That's a quick reply. But I asked her to call, so why did she reply by email? But I decide not to bother. I finish my drink and wander towards Chuo-dori. Then comes an email, almost as if on cue. Don't tell me... is it the mail demon? Tch, it's like she can read my mind. I instinctively scan the area, searching for that gloomy woman in the crowd. No sign of her tailing me. Oh well. I guess I'll send her a reply. I don't know Shining Finger's phone number, so I'll just send her an email for the time being. In the email, I ask her to call, and include my phone number. Now I just have to wait for her response. And there it is. That's a quick reply. But I asked her to call, so why did she reply by email? Wait, she wants it by email? There's a lot to cover. I'd rather not have to type it all out. I need to find out her phone number. Give me your phone number, along with any information you have on the IBN 5100. And... send. I look up after finishing my email and see a huge crowd of people in front of Radi-Kan. I guess the satellite is still a big deal. The media presence hasn't died down since the day of the crash either. Radi-Kan is still closed. And, of course, the satellite is still there. Not 30 seconds pass before I get a reply. Right as I'm about to look down and read the email, I catch sight of a familiar face in the crowd.\"),\n",
       " ('Kurisu', 'Ah.')]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE: DATA INSPECTION CELL #\n",
    "\n",
    "created_examples_script_modified = [i + [(\"NOTE\", \"---NEW_CONV---\")] for i in created_examples_script]\n",
    "created_examples_script_flattened = [item for sublist in created_examples_script_modified for item in sublist]\n",
    "with open(\"script_dump.txt\", \"w\") as f:\n",
    "    f.write('\\n'.join([l[0] + \": \" + l[1] for l in created_examples_script_flattened]))\n",
    "\n",
    "# find out how many examples only have one kurisu line:\n",
    "potentially_bad_examples = [i for i in created_examples_script if len([j for j in i if j[0] == \"Kurisu\"]) == 1]\n",
    "\n",
    "# Take the first of those examples with only one kurisu line and print it out:\n",
    "print(len(potentially_bad_examples))\n",
    "potentially_bad_examples[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK so brief inspection of the script: the conversations are too short and sparse, I need to increase the number of lines without Kurisu for S;G as it is monologue heavy.\n",
    "\n",
    "I'll have to make sure in my annotation prompt that the AI does not add actions to simple thoughts on the part of Okabe. Or maybe it should... so that the model gets used to continuing a train of thought?\n",
    "\n",
    "Results of additional inspection: convs with only 2 Kurisu examples might be removal material; lines with 3 should be kept definitely; lines with 1 are being removed anyway so it doesn't make sense to have min_kurisu_lines be lower than 2\n",
    "\n",
    "Even with the monologue added back in, the phone context is missing. Oh well.\n",
    "\n",
    "Will need to make clear that unspoken can narrate both actions and Okabe's thoughts.\n",
    "\n",
    "Smaller window stops waste at the start of a conversation, smaller max tokens stop waste at end of a conversation, but a smaller window makes it more likely that an example is missed (problem mitigated somewhat now that I'm doing the line merging BEFORE the example generation). A smaller max token size means that some of the really long conversations that are really really good get lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if you want to read in the conversations from preexisting files\n",
    "import os\n",
    "\n",
    "# Previous function to read dialogue from a single file\n",
    "def read_dialogue(file_path):\n",
    "    speaker_line_tuples = []\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            split_line = line.split(\":\", 1)\n",
    "            if len(split_line) == 2:\n",
    "                speaker, line_text = split_line\n",
    "                speaker = speaker.strip()\n",
    "                line_text = line_text.strip()\n",
    "                speaker_line_tuples.append((speaker, line_text))\n",
    "    \n",
    "    return speaker_line_tuples\n",
    "\n",
    "# Function to read dialogues from all files in a directory and sort them by index\n",
    "def read_all_dialogues(directory_path):\n",
    "    # List to store all dialogues (each dialogue is a list of tuples)\n",
    "    all_dialogues = []\n",
    "    \n",
    "    # Get list of all filenames in the directory\n",
    "    filenames = [f for f in os.listdir(directory_path) if f.endswith('_conversation.txt')]\n",
    "    \n",
    "    # Sort filenames by their numerical index\n",
    "    filenames.sort(key=lambda x: int(x.split('_')[0]))\n",
    "    \n",
    "    for filename in filenames:\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        dialogue = read_dialogue(file_path)\n",
    "        all_dialogues.append(dialogue)\n",
    "    \n",
    "    return all_dialogues\n",
    "\n",
    "# Sample usage\n",
    "directory_path = \"./conversations/\"\n",
    "created_examples_script = read_all_dialogues(directory_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Kurisu',\n",
       "  \"I've been looking everywhere for you! Ever since you saved my life. I was afraid I'd never have a chance to say thank you. I'm so glad we could finally meet. Thank you. Thank you so much. And thank goodness you're alright.\"),\n",
       " ('UNSPOKEN',\n",
       "  \"Kurisu looks so radiant as she tries to hold back her tears. Just when I thought I had finally suppressed it, all my love for her flows out at once. I'm so happy that I want to cry too. So, to hide my embarrassment, I take out my phone and put it to my ear.\"),\n",
       " ('Rintaro',\n",
       "  \"It's me. Why is she here? Reading Steiner didn't activate. What? Protect her!? Heh... that's a tall order, my friend. But if that is the choice of Steins Gate... then so be it. El Psy Kongroo.\"),\n",
       " ('UNSPOKEN',\n",
       "  \"I close my phone and clear my throat. I have no idea what to say. She's still staring at me with those wide, pleading eyes. I open my mouth.\"),\n",
       " ('Rintaro', 'We meet again, Christina.'),\n",
       " ('Kurisu',\n",
       "  \"How many times do I have to tell you!? I'm not Christina, or your assistant or--\"),\n",
       " ('Rintaro', '...!?'),\n",
       " ('Kurisu', 'Eh?'),\n",
       " ('UNSPOKEN',\n",
       "  \"Now I really have no idea what to say. How does this Kurisu know about that? Those were the names I used to tease Kurisu. She always got mad whenever I used them. They were our bond, our private joke. But I had yet to use them on the day we first met at Radi-Kan. So how could this worldline's Kurisu know?\"),\n",
       " ('Kurisu',\n",
       "  'Huh? I... why did I say that? Words just... popped into my head...')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "created_examples_script[236]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Tuple List to Training example format\n",
    "def generate_training_examples(conversation):\n",
    "    training_examples = []\n",
    "    temp_dialogue = []\n",
    "    for idx, dialogue in enumerate(conversation):\n",
    "        speaker, _ = dialogue\n",
    "        temp_dialogue.append(dialogue)\n",
    "        if speaker == 'Kurisu' and idx != 0:\n",
    "            training_examples.append(temp_dialogue.copy())  # Add up to and including current line\n",
    "    return training_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('UNSPOKEN',\n",
       "  \"Moeka doesn't seem that interested, but she nods. We set the PhoneWave (name subject to change) to forward to my phone.\"),\n",
       " ('Kurisu', 'Thursday last week... so about five days. Is that okay?'),\n",
       " ('UNSPOKEN',\n",
       "  'Kurisu puts on her lab coat before checking the phone attached to the PhoneWave (name subject to change).'),\n",
       " ('Itaru',\n",
       "  'The drawing was five days ago. It needs to arrive before that, right?'),\n",
       " ('Kurisu',\n",
       "  \"We'll send it to one week ago. 7 days is 168 hours, so let's round up a bit and enter 170#.\")]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "created_examples_script[59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training examples\n",
    "training_data_conversations = list(map(generate_training_examples, created_examples_script))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data_conversations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('UNSPOKEN',\n",
       "   \"Moeka doesn't seem that interested, but she nods. We set the PhoneWave (name subject to change) to forward to my phone.\"),\n",
       "  ('Kurisu', 'Thursday last week... so about five days. Is that okay?')],\n",
       " [('UNSPOKEN',\n",
       "   \"Moeka doesn't seem that interested, but she nods. We set the PhoneWave (name subject to change) to forward to my phone.\"),\n",
       "  ('Kurisu', 'Thursday last week... so about five days. Is that okay?'),\n",
       "  ('UNSPOKEN',\n",
       "   'Kurisu puts on her lab coat before checking the phone attached to the PhoneWave (name subject to change).'),\n",
       "  ('Itaru',\n",
       "   'The drawing was five days ago. It needs to arrive before that, right?'),\n",
       "  ('Kurisu',\n",
       "   \"We'll send it to one week ago. 7 days is 168 hours, so let's round up a bit and enter 170#.\")]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DEBUG # see first element of training convs\n",
    "training_data_conversations[59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Kurisu', 'Okabe!'), ('UNSPOKEN', \"Kurisu's advances on me with a stern glare.\"), ('Kurisu', \"If you want to give me stupid nicknames, that's fine -- I mean, it's not, but... What you said just now is below the belt. I didn't take you for the kind of guy who thinks it's funny to hurt people's feelings, but I guess I was wrong. You're a real jerk, Okabe.\"), ('Rintaro', 'Huh?'), ('UNSPOKEN', 'What did I do to deserve this tongue-lashing?'), ('Kurisu', 'Apologize. Apologize to Urushibara-san right now.'), ('Rintaro', \"Wait a second. I don't have to apologize for anything. I just said the tru--\"), ('Luka', \"It's okay.\"), ('UNSPOKEN', 'Lukako gets up from the sofa. His head is still hanging, and his voice is barely audible.'), ('Luka', \"So that's how Okabe-san sees me...\"), ('Rintaro', \"No no no! That's not how I see you, Lukako. You're a guy, remember!? Or are you denying reality too!?\"), ('Kurisu', \"You're the one denying reality!\"), ('Mayuri', \"That's right! Luka-chan's a girl, Okarin. You're terrible.\"), ('Rintaro', \"Mayuri, when did you start calling Lukako 'Luka-chan' instead of 'Luka-kun'?\"), ('Kurisu', \"Cut it out already, Okabe! She's a girl!\"), ('UNSPOKEN', \"Mayuri nods in agreement. Uh... huh? What's going on here? Is this some kind of prank?\"), ('Luka', \"I'm going home!\"), ('UNSPOKEN', 'Lukako tries to slip by me out of the lab. I grab his hand to stop him from leaving.'), ('Rintaro', \"Hold it, Lukako! You can't fool me! You're as much a man as I am! And I know how to prove it!\"), ('UNSPOKEN', \"I pin Lukako's arms and reach for his package. Let's see what you're hiding... down... Nothing.\"), ('Rintaro', 'Oh...?'), ('Luka', 'ah...'), ('Kurisu', 'You...'), ('Mayuri', 'Awawa...'), ('Rintaro', 'Ohhhh? Huh? What? Why?'), ('UNSPOKEN', 'I feel around some more.'), ('Luka', \"Ugh, no, don't... Okabe-san, please... stop... sniff.\"), ('UNSPOKEN', \"Nothing. Nada. It should be there. I mean, he's a guy... isn't he? An electric current runs through my brain. No way... Yes way. So that's what happened!\"), ('Rintaro', 'Lukako, you...'), ('UNSPOKEN', 'The D-Mail that I thought had failed... Was actually a success!'), ('Rintaro', \"You're a girl!?\"), ('Kurisu', \"That's what we've been saying!\"), ('UNSPOKEN', 'A half-second later, Kurisu cracks me over the head with her heavy textbook.'), ('Luka', 'hic... ugg... egh...'), ('UNSPOKEN', \"When my vision clears, Lukako is crying. Mayuri is rubbing her back comfortingly. Kurisu, meanwhile, is glaring down at me like I'm something she scraped off the bottom of her shoe. Daru, who arrived a moment ago, is in the corner, trying not to laugh. Honestly, I can't blame him.  Righteous High School Girl Makes Perverted College Guy Beg for Forgiveness If I had to put a title to this scene, that's what it would be. The top of my head is throbbing. Most likely because Kurisu wiped out a hundred million of my precious neurons, envied by scientists the world over. I put a moist towel to my head.\"), ('Kurisu', \"I want to vivisect your skull and remove your brain for a good washing. Then I'll submerge it in culture fluid so you can never do anything like that again! Anyway, just be thankful I haven't reported you to the police.\")]\n",
      "237\n"
     ]
    }
   ],
   "source": [
    "training_data_conversations_filtered = list(filter(lambda x: len(x) >= 1, training_data_conversations))\n",
    "# len(processed_conversations)\n",
    "print(training_data_conversations_filtered[99][-1])\n",
    "print(len(training_data_conversations_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from tqdm import tqdm\n",
    "openai.api_key = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_scenario_prompt = [\n",
    "                {\"role\": \"system\", \"content\": \"\"\"You are an expert scenario-writing and prompt-engineering AI. Your task is to write the context for an interaction between Kurisu and Okabe from the visual novel Steins;Gate in a \"scenario\" -- a 5-sentence summary about what's happened until the point the interaction STARTS at (writing under the assumption that the reader knows who Kurisu is, and what some of her general traits are). You should use the lines provided to help determine the context behind a given scene.\n",
    "\n",
    "Remember to keep the scenario at most three sentences long. Your goal is to describe, in generic terms, the conversation's SETTING, at the START of the conversation (as well as what Kurisu is feeling and trying to do) instead of being to summarize it. This context should make sense if the reader only had access to the first line said by Kurisu in the conversation (and the lines immediately preceding it).\n",
    "\n",
    "Think step-by-step, and explain your plan to write an accurate and compelling scenario for the provided context before you actually write the scenario.\n",
    "\n",
    "Here are two roleplay prompt engineering principles you should incorporate into your scenario:\n",
    "1. Your first sentence should explain the context of the scene: where it takes place, what exactly that place is (in general terms) and what each of the characters are doing there. Focus on Rintaro and Kurisu when it comes to motivations.\n",
    "2. End with a statement that describes where the scene is going, specifically, what Kurisu is trying to do.\n",
    "\n",
    "Note that we're using the naming conventions of the visual novel here, so it's 'PhoneWave (name subject to change)', in case that ever comes up.\n",
    "\n",
    "[To help orient you as you determine which part of the plot a conversation is taking in,  here is a plot summary of Steins;Gate:\n",
    "\n",
    "Rintaro, a \"mad scientist,\" meets genius Kurisu at a time travel lecture. They argue, and he later finds her apparently dead. Texting this to his friend Daru activates a prototype time machine, altering the timeline.\n",
    "\n",
    "Kurisu turns out to be alive. Rintaro and friends, including Mayuri and Daru, discover their \"Phone Microwave\" sends texts, or \"D-mails,\" to the past. They use D-mails to fulfill wishes for friends like Moeka, Faris, Luka, and Suzuha. Kurisu joins the lab and helps improve the time machine.\n",
    "\n",
    "Rintaro alone remembers original timelines due to his \"Reading Steiner\" ability. They also create \"Time Leaps,\" sending memories to the past. However, SERN discovers them, raids the lab, and kills Mayuri. Rintaro time-leaps repeatedly but can't save her.\n",
    "\n",
    "To fix things, Rintaro, aided by Kurisu, undoes all D-mails, causing personal pain. They grow closer, but Rintaro realizes the first D-mail about Kurisu's \"death\" caused Mayuri's fate. Undoing it means sacrificing Kurisu, which he reluctantly does to save Mayuri.\n",
    "\n",
    "Time-traveler Suzuha then contacts Rintaro, urging him to prevent World War 3 by saving Kurisu. Rintaro accidentally kills her himself, but gets advice from his future self on reaching a timeline—Steins Gate—where both friends live. He succeeds by faking Kurisu's death.\n",
    "\n",
    "In the Steins Gate timeline, Rintaro and Kurisu encounter each other, experiencing déjà vu from past timelines.]\n",
    "\n",
    "Take special care to write a scenario that would make sense to someone ignorant of the overall plot of Steins;Gate. IE, you are not just trying to write a scenario that makes sense only when viewed alongside the plot summary; you are writing something that gives adequate context to a scene by itself alone. Instead of using Steins;Gate specific terminology, you will use generic words and explanations to give context to a scene.\n",
    "\n",
    "Note that UNSPOKEN lines can either be narration about what's happening, or Okabe's thoughts; they're all from Okabe's point of view, however.\n",
    "\n",
    "One last pointer: keep the language simple. Which characters are where, under what circumstances, and what Kurisu is feeling and will do. The scene itself will do most of the talking. Keep the scenario 5 sentences long at most. Instead of mentioning events in the far future, you will concentrate on the event at hand and the things that led up to it.\"\"\"},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"Context: \\\"\\\"\\\"Okabe: Who the hell am I!? Someone who knows you for a fraud, that’s who! You stole your theory from John Titor! And you call yourself an inventor!?\n",
    "Nakabachi: S-someone throw this man out!\n",
    "Okabe: You're the one we should throw out, Doctor! Have you no shame!? You have no right to call yourself an inventor!\n",
    "Nakabachi: Shut your mouth, you little pest!\n",
    "UNSPOKEN: Just then, someone grabs my arm from behind. Quite convinced it's an official here to throw me out, I turn around to glare him down.\n",
    "Okabe: Unhand me, you... huh?\n",
    "UNSPOKEN: It's a girl about my age. Her intense stare seems to challenge me. I take a step back. Her face looks somehow familiar. Where have I seen her before?\n",
    "Okabe: Ah...\n",
    "UNSPOKEN: We haven't met, but I know her face. It's Makise Kurisu. A few days ago, my friend Daru showed me a magazine article titled Girl Genius Gives Lecture in Akihabara. The article was about a 17-year-old girl who had just graduated from an American university. Her thesis was even published in a major scientific journal. Girl Genius, Makise Kurisu. I recognize the stubborn-looking girl from her photograph. She's even wearing the exact same scowl. What business could such a genius have with me? She takes a quick look around the room, then turns back to me with a stern expression.\n",
    "Kurisu: Could you come with me for a moment?\n",
    "UNSPOKEN: What's with the attitude? She's obviously not staff, and there's no way that the Makise Kurisu would be working with someone like Doctor Nakabachi. Which means... no!\n",
    "Okabe: Y-you're with the Organization!?\n",
    "Kurisu: Huh?\n",
    "Okabe: If their tendrils have gotten this far, then I've made a grave mistake.\n",
    "Kurisu: Stop fooling around and come with me.\n",
    "UNSPOKEN: My outburst has already attracted too much attention. Nakabachi, in particular, looks like he wants to rip my head off. It must be mortifying to be exposed as a fraud by a bright young man like myself. Anyway, I mustn’t draw any more attention to myself. If the Organization gets wind of my presence here, it could endanger Mayuri -- to say nothing of these ignorant civilians. I let Makise Kurisu lead me out of the assembly hall.\n",
    "Okabe: Try anything and people are sure to notice. What will your superiors say then?\n",
    "Kurisu: What are you talking about?\\\"\\\"\\\"\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\" : \"assistant\",\n",
    "        \"content\": \"\"\"Plan:\n",
    "1. Start by describing the setting and the ongoing event - a lecture where Okabe causes a scene. \n",
    "2. Describe what kind of person Okabe is. Nakabachi is not involved in the main conversation with Kurisu, so I will not explain who he is.\n",
    "3. Mention Kurisu's relation to Okabe, that they are meeting for the first time.\n",
    "4. Describe Kurisu's current state, slightly puzzled and intrigued by Okabe's outburst and behavior.\n",
    "5. Conclude by stating Kurisu's intention - to find out what Okabe was trying to tell her.\n",
    "6. Do not mention anything that occurs after the first few lines Kurisu speaks.\n",
    "\n",
    "Scenario:\n",
    "In the midst of a heated lecture, Okabe, an eccentric young man, stirs up an argument, accusing the speaker of plagiarism. Kurisu is in the crowd observing the spectacle, and believes Okabe had tried to tell her something earlier (Okabe believes that he's never met Kurisu). This is the first time Kurisu and Okabe meet, and she finds Okabe's erratic behavior puzzling yet intriguing. Intrigued by Okabe's strange behavior and apparent knowledge of her, Kurisu decides to approach him during the lecture with the intention of uncovering what he was trying to communicate to her earlier.\"\"\"\n",
    "    },\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A FUNCTION THAT LETS YOU CALL OPENAI ON ALL THE EXAMPLES\n",
    "import openai\n",
    "import os\n",
    "\n",
    "def write_context_to_file(training_data_example, destination_directory, example_index): # for easier inspection\n",
    "    \"\"\"Writes a training example (conversation, the full thing) to a file in the destination directory, so that the input for a scenario can be inspected\"\"\"\n",
    "    full_conversation = training_data_example[-1]\n",
    "    context = '\\n'.join([f'{speaker}: {line}' for speaker, line in full_conversation])\n",
    "    \n",
    "    filename = os.path.join(destination_directory, f'{example_index:03d}_conversation.txt') # I'm paying for the tokens, I damn well want to see them\n",
    "\n",
    "    # Write the scenario to the file\n",
    "    with open(filename, 'w') as f_1:\n",
    "        f_1.write(context)\n",
    "\n",
    "for idx, content in enumerate(training_data_conversations_filtered):\n",
    "    \"\"\"Write all training examples to indexed files\"\"\"\n",
    "    write_context_to_file(content, 'conversations', idx)\n",
    "    \n",
    "\n",
    "def create_scenario(training_data_example, destination_directory, example_index):\n",
    "    \"\"\"Creates a scenario for a training example and writes it to a file in the destination directory\"\"\"\n",
    "    full_conversation = training_data_example[-1]\n",
    "    context = '\\n'.join([f'{speaker}: {line}' for speaker, line in full_conversation])\n",
    "\n",
    "    if not os.path.exists(os.path.join(destination_directory, f'{example_index:03d}_cot_debug.txt')):\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4\",\n",
    "            temperature=0.7,\n",
    "            # top_p = 0.9,\n",
    "            messages=openai_scenario_prompt + [{\n",
    "                \"role\" : \"user\",\n",
    "            \"content\" : f\"\"\"Context (do not forget to mention in your final response how well Kurisu knows all of the characters present in this scene): \\\"\\\"\\\"{context.replace(\"Rintaro:\",\"Okabe:\")}\\\"\\\"\\\"\n",
    "            \n",
    "Remember that:\n",
    "1. The scenario you write should assume complete knowledge of who Kurisu is (it should not introduce her), but must state her relation to the other characters in the scene.\n",
    "2. The scenario you write should set up the scene, not summarize it, and not hint at its conclusion. It describes the moment up to Kurisu's first message.\n",
    "3. DON'T actually metion that this is happening during Steins;Gate, and don't describe elements of the plot that aren't related to the ongoing scene. Be FOCUSED.\n",
    "4. Follow the rough format (don't copy the words verbatim, but the order should generally be preserved: Because of [brief background explaining that scene that can be understood by a generic reader] Kurisu is at [setting] along with [other character(s) who are directly involved in the interactions between Kurisu and Okabe]. Kurisu knows [characters] [well or not well, positively or negatively]. Kurisu is trying to [do something (that involves Okabe)].\n",
    "5. If the lines shown cover multiple scenes, focus only on the first one that involves both Okabe and Kurisu speaking.\n",
    "6. You don't have to introduce who Kurisu or Okabe are, but you should briefly mention who the other characters are.\n",
    "\n",
    "Don't forget to plan out your final answer before you write it. At least 4 bullet points of thought process are recommended.\"\"\"\n",
    "            }]\n",
    "        )\n",
    "    \n",
    "        scenario = response['choices'][0]['message']['content']\n",
    "        \n",
    "        filename_cot_debug = os.path.join(destination_directory, f'{example_index:03d}_cot_debug.txt') # I'm paying for the tokens, I damn well want to see them\n",
    "\n",
    "        # Write the scenario to the file\n",
    "        with open(filename_cot_debug, 'w') as f_1:\n",
    "            f_1.write(scenario)\n",
    "\n",
    "        # # Assume \"Scenario:\\n\" is followed by the actual scenario\n",
    "        scenario = re.search('Scenario:(.*)', scenario, re.DOTALL).group(1)\n",
    "\n",
    "        # Create a filename based on the example index\n",
    "        filename = os.path.join(destination_directory, f'{example_index:03d}.txt')\n",
    "\n",
    "        # Write the scenario to the file\n",
    "        with open(filename, 'w') as f_2:\n",
    "            f_2.write(scenario)\n",
    "    else:\n",
    "        print(f\"Skipping {example_index:03d} because it already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 237/237 [00:00<00:00, 45134.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 000 because it already exists.\n",
      "Skipping 001 because it already exists.\n",
      "Skipping 002 because it already exists.\n",
      "Skipping 003 because it already exists.\n",
      "Skipping 004 because it already exists.\n",
      "Skipping 005 because it already exists.\n",
      "Skipping 006 because it already exists.\n",
      "Skipping 007 because it already exists.\n",
      "Skipping 008 because it already exists.\n",
      "Skipping 009 because it already exists.\n",
      "Skipping 010 because it already exists.\n",
      "Skipping 011 because it already exists.\n",
      "Skipping 012 because it already exists.\n",
      "Skipping 013 because it already exists.\n",
      "Skipping 014 because it already exists.\n",
      "Skipping 015 because it already exists.\n",
      "Skipping 016 because it already exists.\n",
      "Skipping 017 because it already exists.\n",
      "Skipping 018 because it already exists.\n",
      "Skipping 019 because it already exists.\n",
      "Skipping 020 because it already exists.\n",
      "Skipping 021 because it already exists.\n",
      "Skipping 022 because it already exists.\n",
      "Skipping 023 because it already exists.\n",
      "Skipping 024 because it already exists.\n",
      "Skipping 025 because it already exists.\n",
      "Skipping 026 because it already exists.\n",
      "Skipping 027 because it already exists.\n",
      "Skipping 028 because it already exists.\n",
      "Skipping 029 because it already exists.\n",
      "Skipping 030 because it already exists.\n",
      "Skipping 031 because it already exists.\n",
      "Skipping 032 because it already exists.\n",
      "Skipping 033 because it already exists.\n",
      "Skipping 034 because it already exists.\n",
      "Skipping 035 because it already exists.\n",
      "Skipping 036 because it already exists.\n",
      "Skipping 037 because it already exists.\n",
      "Skipping 038 because it already exists.\n",
      "Skipping 039 because it already exists.\n",
      "Skipping 040 because it already exists.\n",
      "Skipping 041 because it already exists.\n",
      "Skipping 042 because it already exists.\n",
      "Skipping 043 because it already exists.\n",
      "Skipping 044 because it already exists.\n",
      "Skipping 045 because it already exists.\n",
      "Skipping 046 because it already exists.\n",
      "Skipping 047 because it already exists.\n",
      "Skipping 048 because it already exists.\n",
      "Skipping 049 because it already exists.\n",
      "Skipping 050 because it already exists.\n",
      "Skipping 051 because it already exists.\n",
      "Skipping 052 because it already exists.\n",
      "Skipping 053 because it already exists.\n",
      "Skipping 054 because it already exists.\n",
      "Skipping 055 because it already exists.\n",
      "Skipping 056 because it already exists.\n",
      "Skipping 057 because it already exists.\n",
      "Skipping 058 because it already exists.\n",
      "Skipping 059 because it already exists.\n",
      "Skipping 060 because it already exists.\n",
      "Skipping 061 because it already exists.\n",
      "Skipping 062 because it already exists.\n",
      "Skipping 063 because it already exists.\n",
      "Skipping 064 because it already exists.\n",
      "Skipping 065 because it already exists.\n",
      "Skipping 066 because it already exists.\n",
      "Skipping 067 because it already exists.\n",
      "Skipping 068 because it already exists.\n",
      "Skipping 069 because it already exists.\n",
      "Skipping 070 because it already exists.\n",
      "Skipping 071 because it already exists.\n",
      "Skipping 072 because it already exists.\n",
      "Skipping 073 because it already exists.\n",
      "Skipping 074 because it already exists.\n",
      "Skipping 075 because it already exists.\n",
      "Skipping 076 because it already exists.\n",
      "Skipping 077 because it already exists.\n",
      "Skipping 078 because it already exists.\n",
      "Skipping 079 because it already exists.\n",
      "Skipping 080 because it already exists.\n",
      "Skipping 081 because it already exists.\n",
      "Skipping 082 because it already exists.\n",
      "Skipping 083 because it already exists.\n",
      "Skipping 084 because it already exists.\n",
      "Skipping 085 because it already exists.\n",
      "Skipping 086 because it already exists.\n",
      "Skipping 087 because it already exists.\n",
      "Skipping 088 because it already exists.\n",
      "Skipping 089 because it already exists.\n",
      "Skipping 090 because it already exists.\n",
      "Skipping 091 because it already exists.\n",
      "Skipping 092 because it already exists.\n",
      "Skipping 093 because it already exists.\n",
      "Skipping 094 because it already exists.\n",
      "Skipping 095 because it already exists.\n",
      "Skipping 096 because it already exists.\n",
      "Skipping 097 because it already exists.\n",
      "Skipping 098 because it already exists.\n",
      "Skipping 099 because it already exists.\n",
      "Skipping 100 because it already exists.\n",
      "Skipping 101 because it already exists.\n",
      "Skipping 102 because it already exists.\n",
      "Skipping 103 because it already exists.\n",
      "Skipping 104 because it already exists.\n",
      "Skipping 105 because it already exists.\n",
      "Skipping 106 because it already exists.\n",
      "Skipping 107 because it already exists.\n",
      "Skipping 108 because it already exists.\n",
      "Skipping 109 because it already exists.\n",
      "Skipping 110 because it already exists.\n",
      "Skipping 111 because it already exists.\n",
      "Skipping 112 because it already exists.\n",
      "Skipping 113 because it already exists.\n",
      "Skipping 114 because it already exists.\n",
      "Skipping 115 because it already exists.\n",
      "Skipping 116 because it already exists.\n",
      "Skipping 117 because it already exists.\n",
      "Skipping 118 because it already exists.\n",
      "Skipping 119 because it already exists.\n",
      "Skipping 120 because it already exists.\n",
      "Skipping 121 because it already exists.\n",
      "Skipping 122 because it already exists.\n",
      "Skipping 123 because it already exists.\n",
      "Skipping 124 because it already exists.\n",
      "Skipping 125 because it already exists.\n",
      "Skipping 126 because it already exists.\n",
      "Skipping 127 because it already exists.\n",
      "Skipping 128 because it already exists.\n",
      "Skipping 129 because it already exists.\n",
      "Skipping 130 because it already exists.\n",
      "Skipping 131 because it already exists.\n",
      "Skipping 132 because it already exists.\n",
      "Skipping 133 because it already exists.\n",
      "Skipping 134 because it already exists.\n",
      "Skipping 135 because it already exists.\n",
      "Skipping 136 because it already exists.\n",
      "Skipping 137 because it already exists.\n",
      "Skipping 138 because it already exists.\n",
      "Skipping 139 because it already exists.\n",
      "Skipping 140 because it already exists.\n",
      "Skipping 141 because it already exists.\n",
      "Skipping 142 because it already exists.\n",
      "Skipping 143 because it already exists.\n",
      "Skipping 144 because it already exists.\n",
      "Skipping 145 because it already exists.\n",
      "Skipping 146 because it already exists.\n",
      "Skipping 147 because it already exists.\n",
      "Skipping 148 because it already exists.\n",
      "Skipping 149 because it already exists.\n",
      "Skipping 150 because it already exists.\n",
      "Skipping 151 because it already exists.\n",
      "Skipping 152 because it already exists.\n",
      "Skipping 153 because it already exists.\n",
      "Skipping 154 because it already exists.\n",
      "Skipping 155 because it already exists.\n",
      "Skipping 156 because it already exists.\n",
      "Skipping 157 because it already exists.\n",
      "Skipping 158 because it already exists.\n",
      "Skipping 159 because it already exists.\n",
      "Skipping 160 because it already exists.\n",
      "Skipping 161 because it already exists.\n",
      "Skipping 162 because it already exists.\n",
      "Skipping 163 because it already exists.\n",
      "Skipping 164 because it already exists.\n",
      "Skipping 165 because it already exists.\n",
      "Skipping 166 because it already exists.\n",
      "Skipping 167 because it already exists.\n",
      "Skipping 168 because it already exists.\n",
      "Skipping 169 because it already exists.\n",
      "Skipping 170 because it already exists.\n",
      "Skipping 171 because it already exists.\n",
      "Skipping 172 because it already exists.\n",
      "Skipping 173 because it already exists.\n",
      "Skipping 174 because it already exists.\n",
      "Skipping 175 because it already exists.\n",
      "Skipping 176 because it already exists.\n",
      "Skipping 177 because it already exists.\n",
      "Skipping 178 because it already exists.\n",
      "Skipping 179 because it already exists.\n",
      "Skipping 180 because it already exists.\n",
      "Skipping 181 because it already exists.\n",
      "Skipping 182 because it already exists.\n",
      "Skipping 183 because it already exists.\n",
      "Skipping 184 because it already exists.\n",
      "Skipping 185 because it already exists.\n",
      "Skipping 186 because it already exists.\n",
      "Skipping 187 because it already exists.\n",
      "Skipping 188 because it already exists.\n",
      "Skipping 189 because it already exists.\n",
      "Skipping 190 because it already exists.\n",
      "Skipping 191 because it already exists.\n",
      "Skipping 192 because it already exists.\n",
      "Skipping 193 because it already exists.\n",
      "Skipping 194 because it already exists.\n",
      "Skipping 195 because it already exists.\n",
      "Skipping 196 because it already exists.\n",
      "Skipping 197 because it already exists.\n",
      "Skipping 198 because it already exists.\n",
      "Skipping 199 because it already exists.\n",
      "Skipping 200 because it already exists.\n",
      "Skipping 201 because it already exists.\n",
      "Skipping 202 because it already exists.\n",
      "Skipping 203 because it already exists.\n",
      "Skipping 204 because it already exists.\n",
      "Skipping 205 because it already exists.\n",
      "Skipping 206 because it already exists.\n",
      "Skipping 207 because it already exists.\n",
      "Skipping 208 because it already exists.\n",
      "Skipping 209 because it already exists.\n",
      "Skipping 210 because it already exists.\n",
      "Skipping 211 because it already exists.\n",
      "Skipping 212 because it already exists.\n",
      "Skipping 213 because it already exists.\n",
      "Skipping 214 because it already exists.\n",
      "Skipping 215 because it already exists.\n",
      "Skipping 216 because it already exists.\n",
      "Skipping 217 because it already exists.\n",
      "Skipping 218 because it already exists.\n",
      "Skipping 219 because it already exists.\n",
      "Skipping 220 because it already exists.\n",
      "Skipping 221 because it already exists.\n",
      "Skipping 222 because it already exists.\n",
      "Skipping 223 because it already exists.\n",
      "Skipping 224 because it already exists.\n",
      "Skipping 225 because it already exists.\n",
      "Skipping 226 because it already exists.\n",
      "Skipping 227 because it already exists.\n",
      "Skipping 228 because it already exists.\n",
      "Skipping 229 because it already exists.\n",
      "Skipping 230 because it already exists.\n",
      "Skipping 231 because it already exists.\n",
      "Skipping 232 because it already exists.\n",
      "Skipping 233 because it already exists.\n",
      "Skipping 234 because it already exists.\n",
      "Skipping 235 because it already exists.\n",
      "Skipping 236 because it already exists.\n",
      "\n",
      "Beginning Second Pass...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 237/237 [00:00<00:00, 60801.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 000 because it already exists.\n",
      "Skipping 001 because it already exists.\n",
      "Skipping 002 because it already exists.\n",
      "Skipping 003 because it already exists.\n",
      "Skipping 004 because it already exists.\n",
      "Skipping 005 because it already exists.\n",
      "Skipping 006 because it already exists.\n",
      "Skipping 007 because it already exists.\n",
      "Skipping 008 because it already exists.\n",
      "Skipping 009 because it already exists.\n",
      "Skipping 010 because it already exists.\n",
      "Skipping 011 because it already exists.\n",
      "Skipping 012 because it already exists.\n",
      "Skipping 013 because it already exists.\n",
      "Skipping 014 because it already exists.\n",
      "Skipping 015 because it already exists.\n",
      "Skipping 016 because it already exists.\n",
      "Skipping 017 because it already exists.\n",
      "Skipping 018 because it already exists.\n",
      "Skipping 019 because it already exists.\n",
      "Skipping 020 because it already exists.\n",
      "Skipping 021 because it already exists.\n",
      "Skipping 022 because it already exists.\n",
      "Skipping 023 because it already exists.\n",
      "Skipping 024 because it already exists.\n",
      "Skipping 025 because it already exists.\n",
      "Skipping 026 because it already exists.\n",
      "Skipping 027 because it already exists.\n",
      "Skipping 028 because it already exists.\n",
      "Skipping 029 because it already exists.\n",
      "Skipping 030 because it already exists.\n",
      "Skipping 031 because it already exists.\n",
      "Skipping 032 because it already exists.\n",
      "Skipping 033 because it already exists.\n",
      "Skipping 034 because it already exists.\n",
      "Skipping 035 because it already exists.\n",
      "Skipping 036 because it already exists.\n",
      "Skipping 037 because it already exists.\n",
      "Skipping 038 because it already exists.\n",
      "Skipping 039 because it already exists.\n",
      "Skipping 040 because it already exists.\n",
      "Skipping 041 because it already exists.\n",
      "Skipping 042 because it already exists.\n",
      "Skipping 043 because it already exists.\n",
      "Skipping 044 because it already exists.\n",
      "Skipping 045 because it already exists.\n",
      "Skipping 046 because it already exists.\n",
      "Skipping 047 because it already exists.\n",
      "Skipping 048 because it already exists.\n",
      "Skipping 049 because it already exists.\n",
      "Skipping 050 because it already exists.\n",
      "Skipping 051 because it already exists.\n",
      "Skipping 052 because it already exists.\n",
      "Skipping 053 because it already exists.\n",
      "Skipping 054 because it already exists.\n",
      "Skipping 055 because it already exists.\n",
      "Skipping 056 because it already exists.\n",
      "Skipping 057 because it already exists.\n",
      "Skipping 058 because it already exists.\n",
      "Skipping 059 because it already exists.\n",
      "Skipping 060 because it already exists.\n",
      "Skipping 061 because it already exists.\n",
      "Skipping 062 because it already exists.\n",
      "Skipping 063 because it already exists.\n",
      "Skipping 064 because it already exists.\n",
      "Skipping 065 because it already exists.\n",
      "Skipping 066 because it already exists.\n",
      "Skipping 067 because it already exists.\n",
      "Skipping 068 because it already exists.\n",
      "Skipping 069 because it already exists.\n",
      "Skipping 070 because it already exists.\n",
      "Skipping 071 because it already exists.\n",
      "Skipping 072 because it already exists.\n",
      "Skipping 073 because it already exists.\n",
      "Skipping 074 because it already exists.\n",
      "Skipping 075 because it already exists.\n",
      "Skipping 076 because it already exists.\n",
      "Skipping 077 because it already exists.\n",
      "Skipping 078 because it already exists.\n",
      "Skipping 079 because it already exists.\n",
      "Skipping 080 because it already exists.\n",
      "Skipping 081 because it already exists.\n",
      "Skipping 082 because it already exists.\n",
      "Skipping 083 because it already exists.\n",
      "Skipping 084 because it already exists.\n",
      "Skipping 085 because it already exists.\n",
      "Skipping 086 because it already exists.\n",
      "Skipping 087 because it already exists.\n",
      "Skipping 088 because it already exists.\n",
      "Skipping 089 because it already exists.\n",
      "Skipping 090 because it already exists.\n",
      "Skipping 091 because it already exists.\n",
      "Skipping 092 because it already exists.\n",
      "Skipping 093 because it already exists.\n",
      "Skipping 094 because it already exists.\n",
      "Skipping 095 because it already exists.\n",
      "Skipping 096 because it already exists.\n",
      "Skipping 097 because it already exists.\n",
      "Skipping 098 because it already exists.\n",
      "Skipping 099 because it already exists.\n",
      "Skipping 100 because it already exists.\n",
      "Skipping 101 because it already exists.\n",
      "Skipping 102 because it already exists.\n",
      "Skipping 103 because it already exists.\n",
      "Skipping 104 because it already exists.\n",
      "Skipping 105 because it already exists.\n",
      "Skipping 106 because it already exists.\n",
      "Skipping 107 because it already exists.\n",
      "Skipping 108 because it already exists.\n",
      "Skipping 109 because it already exists.\n",
      "Skipping 110 because it already exists.\n",
      "Skipping 111 because it already exists.\n",
      "Skipping 112 because it already exists.\n",
      "Skipping 113 because it already exists.\n",
      "Skipping 114 because it already exists.\n",
      "Skipping 115 because it already exists.\n",
      "Skipping 116 because it already exists.\n",
      "Skipping 117 because it already exists.\n",
      "Skipping 118 because it already exists.\n",
      "Skipping 119 because it already exists.\n",
      "Skipping 120 because it already exists.\n",
      "Skipping 121 because it already exists.\n",
      "Skipping 122 because it already exists.\n",
      "Skipping 123 because it already exists.\n",
      "Skipping 124 because it already exists.\n",
      "Skipping 125 because it already exists.\n",
      "Skipping 126 because it already exists.\n",
      "Skipping 127 because it already exists.\n",
      "Skipping 128 because it already exists.\n",
      "Skipping 129 because it already exists.\n",
      "Skipping 130 because it already exists.\n",
      "Skipping 131 because it already exists.\n",
      "Skipping 132 because it already exists.\n",
      "Skipping 133 because it already exists.\n",
      "Skipping 134 because it already exists.\n",
      "Skipping 135 because it already exists.\n",
      "Skipping 136 because it already exists.\n",
      "Skipping 137 because it already exists.\n",
      "Skipping 138 because it already exists.\n",
      "Skipping 139 because it already exists.\n",
      "Skipping 140 because it already exists.\n",
      "Skipping 141 because it already exists.\n",
      "Skipping 142 because it already exists.\n",
      "Skipping 143 because it already exists.\n",
      "Skipping 144 because it already exists.\n",
      "Skipping 145 because it already exists.\n",
      "Skipping 146 because it already exists.\n",
      "Skipping 147 because it already exists.\n",
      "Skipping 148 because it already exists.\n",
      "Skipping 149 because it already exists.\n",
      "Skipping 150 because it already exists.\n",
      "Skipping 151 because it already exists.\n",
      "Skipping 152 because it already exists.\n",
      "Skipping 153 because it already exists.\n",
      "Skipping 154 because it already exists.\n",
      "Skipping 155 because it already exists.\n",
      "Skipping 156 because it already exists.\n",
      "Skipping 157 because it already exists.\n",
      "Skipping 158 because it already exists.\n",
      "Skipping 159 because it already exists.\n",
      "Skipping 160 because it already exists.\n",
      "Skipping 161 because it already exists.\n",
      "Skipping 162 because it already exists.\n",
      "Skipping 163 because it already exists.\n",
      "Skipping 164 because it already exists.\n",
      "Skipping 165 because it already exists.\n",
      "Skipping 166 because it already exists.\n",
      "Skipping 167 because it already exists.\n",
      "Skipping 168 because it already exists.\n",
      "Skipping 169 because it already exists.\n",
      "Skipping 170 because it already exists.\n",
      "Skipping 171 because it already exists.\n",
      "Skipping 172 because it already exists.\n",
      "Skipping 173 because it already exists.\n",
      "Skipping 174 because it already exists.\n",
      "Skipping 175 because it already exists.\n",
      "Skipping 176 because it already exists.\n",
      "Skipping 177 because it already exists.\n",
      "Skipping 178 because it already exists.\n",
      "Skipping 179 because it already exists.\n",
      "Skipping 180 because it already exists.\n",
      "Skipping 181 because it already exists.\n",
      "Skipping 182 because it already exists.\n",
      "Skipping 183 because it already exists.\n",
      "Skipping 184 because it already exists.\n",
      "Skipping 185 because it already exists.\n",
      "Skipping 186 because it already exists.\n",
      "Skipping 187 because it already exists.\n",
      "Skipping 188 because it already exists.\n",
      "Skipping 189 because it already exists.\n",
      "Skipping 190 because it already exists.\n",
      "Skipping 191 because it already exists.\n",
      "Skipping 192 because it already exists.\n",
      "Skipping 193 because it already exists.\n",
      "Skipping 194 because it already exists.\n",
      "Skipping 195 because it already exists.\n",
      "Skipping 196 because it already exists.\n",
      "Skipping 197 because it already exists.\n",
      "Skipping 198 because it already exists.\n",
      "Skipping 199 because it already exists.\n",
      "Skipping 200 because it already exists.\n",
      "Skipping 201 because it already exists.\n",
      "Skipping 202 because it already exists.\n",
      "Skipping 203 because it already exists.\n",
      "Skipping 204 because it already exists.\n",
      "Skipping 205 because it already exists.\n",
      "Skipping 206 because it already exists.\n",
      "Skipping 207 because it already exists.\n",
      "Skipping 208 because it already exists.\n",
      "Skipping 209 because it already exists.\n",
      "Skipping 210 because it already exists.\n",
      "Skipping 211 because it already exists.\n",
      "Skipping 212 because it already exists.\n",
      "Skipping 213 because it already exists.\n",
      "Skipping 214 because it already exists.\n",
      "Skipping 215 because it already exists.\n",
      "Skipping 216 because it already exists.\n",
      "Skipping 217 because it already exists.\n",
      "Skipping 218 because it already exists.\n",
      "Skipping 219 because it already exists.\n",
      "Skipping 220 because it already exists.\n",
      "Skipping 221 because it already exists.\n",
      "Skipping 222 because it already exists.\n",
      "Skipping 223 because it already exists.\n",
      "Skipping 224 because it already exists.\n",
      "Skipping 225 because it already exists.\n",
      "Skipping 226 because it already exists.\n",
      "Skipping 227 because it already exists.\n",
      "Skipping 228 because it already exists.\n",
      "Skipping 229 because it already exists.\n",
      "Skipping 230 because it already exists.\n",
      "Skipping 231 because it already exists.\n",
      "Skipping 232 because it already exists.\n",
      "Skipping 233 because it already exists.\n",
      "Skipping 234 because it already exists.\n",
      "Skipping 235 because it already exists.\n",
      "Skipping 236 because it already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# NOTE WARNING -- THIS CELL SPENDS MONEY IF YOU HAVE NOT GENERATED TRAINING EXAMPLES YET.\n",
    "# If you have not generated training examples yet, this cell will generate them and then generate scenarios for them.\n",
    "\n",
    "for idx, content in enumerate(tqdm(training_data_conversations_filtered)):\n",
    "    # write_context_to_file(content, 'contexts', idx)\n",
    "    create_scenario(content, 'scenarios', idx)\n",
    "\n",
    "print(\"\\nBeginning Second Pass...\\n\")\n",
    "\n",
    "for idx, content in enumerate(tqdm(training_data_conversations_filtered)): # run it again to catch everything that failed the first time. The fact that already-generated scenarios are skipped means this doesn't cost any unneeded money.\n",
    "    # write_context_to_file(content, 'contexts', idx)\n",
    "    create_scenario(content, 'scenarios', idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get scenarios back into notebook data from files\n",
    "\n",
    "# read off every scenario, and make a list of them that lines up with the training data\n",
    "def make_scenario_list(training_data_conversations):\n",
    "    scenario_list = []\n",
    "    for idx, content in enumerate(training_data_conversations):\n",
    "        with open(f\"scenarios/{idx:03d}.txt\", \"r\") as f:\n",
    "            scenario_list.append(f.read())\n",
    "    return scenario_list\n",
    "\n",
    "scenarios = make_scenario_list(training_data_conversations_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_prompt = [\n",
    "                {\"role\": \"system\", \"content\": \"\"\"For the rest of this conversation, you are an expert roleplaying AI with deep understanding of internet roleplay formats. I need your assistance in annotating a dataset of lines from the Visual Novel Steins;Gate. Since Steins;Gate is a visual novel, the dialogue is written without much indication of the physical actions any characters are performing. You are going to add physical actions done by the characters to their voice lines in a compelling, narrative way, that make senses in the context of the scene you're modifying. Actions should be surrounded by asterisks, and things the charactes say should be surrounded by double quotes (\"\"). You may also find it useful to add non-action, non-dialogue text to characters' responses, (such as 'she says' or other such generic connective terms) to make sentences make sense.\n",
    " \n",
    "In case I was unclear about what I mean by \"physical actions the characters are taking\", consider this example I just made up on the spot:\n",
    "\n",
    "```\n",
    "Character: \"You fool,\" *character rolls her eyes in exasperation, raising her voice* \"this is fundamental internet roleplay stuff, of course I know how it works!\" she says.\n",
    "```\n",
    "\n",
    "Write character responses in the tense shown in the example above, except for Okabe Rintaro, whose lines should be adapted to be in the first person. So for instance:\n",
    "\n",
    "```\n",
    "Okabe: \"This is the choice of Steins Gate!\" *I strike a pose.* \"Muahahaha!\" I finish my exposition by laughing manaically.\n",
    "```\n",
    "Some detailed instructions:\n",
    "* Keep spoken lines intact; these are in \"quotes.\"\n",
    "* Add actions and novel-like connective text to make dialogue more roleplay-like.\n",
    "    * Make it logical, narratively compelling, but not verbose.\n",
    "* Refer to Okabe Rintaro in other characters' actions the same way the unspoken lines do -- as \"me\".\n",
    "    * Example: Kurisu: \"...So you talk to yourself.\" *She raises an eyebrow, clearly questioning my sanity.*\n",
    "* Use characters' names for actions when not referring to Okabe.\n",
    "    * Example: Kurisu: \"Can't be too careful around the perv duo,\" *She shoots a glare at Daru.*\n",
    "* Outline the roleplay scene before writing.\n",
    "    * Analyze the dialogue to understand what's happening physically.\n",
    "    * Brainstorm character actions to reveal emotions and thoughts.\n",
    "* Start roleplay text with \"Roleplay:\".\n",
    "* Follow Steins;Gate VN naming conventions, e.g., 'PhoneWave (name subject to change)'.\n",
    "* For Okabe's actions, use character's name or pronoun instead of \"your.\"\n",
    "    * Example: I wonder what she's doing (not I wonder what you're doing).\n",
    "* For interrupted sentences, split and insert the interrupting action.\n",
    "    * Example: Okabe \"I'll find a way to--\\nKurisu: *snatches phone*\\nOkabe \"What are you doing!?\" *I stammer.*\n",
    "    * The interrupting character should not say new lines; only add actions.\n",
    "* If unsure about adding an action for an interruption, leave the line as-is.\n",
    "* Add *actions* to the ENTIRE scene, even minor ones will do.\n",
    "* If a scene transition (for instance, Okabe and Kurisu leaving an assembly hall) can be explained with an *action*, add one that makes the transition between scenes manageable.\"\"\"},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"Scenario/setting: \\\"\\\"\\\"In the midst of a heated lecture, Okabe, an eccentric young man, stirs up an argument, accusing the speaker of plagiarism. Kurisu is in the crowd observing the spectacle, and believes Okabe had tried to tell her something earlier (Okabe believes that he's never met Kurisu). This is the first time Kurisu and Okabe meet, and she finds Okabe's erratic behavior puzzling yet intriguing. Intrigued by Okabe's strange behavior and apparent knowledge of her, Kurisu decides to approach him during the lecture with the intention of uncovering what he was trying to communicate to her earlier.\\\"\\\"\\\"\n",
    "\n",
    "Dialogue for reformatting:\n",
    "\\\"\\\"\\\"\n",
    "Okabe: Who the hell am I!? Someone who knows you for a fraud, that's who! You stole your theory from John Titor! And you call yourself an inventor!?\n",
    "\n",
    "Nakabachi: S-someone throw this man out!\n",
    "\n",
    "Okabe: You're the one we should throw out, Doctor! Have you no shame!? You have no right to call yourself an inventor!\n",
    "\n",
    "Nakabachi: Shut your mouth, you little pest!\n",
    "\n",
    "UNSPOKEN: Just then, someone grabs my arm from behind. Quite convinced it's an official here to throw me out, I turn around to glare him down.\n",
    "\n",
    "Okabe: Unhand me, you... huh?\n",
    "\n",
    "UNSPOKEN: It's a girl about my age. Her intense stare seems to challenge me. I take a step back. Her face looks somehow familiar. Where have I seen her before?\n",
    "\n",
    "Okabe: Ah...\n",
    "\n",
    "UNSPOKEN: We haven't met, but I know her face. It's Makise Kurisu. A few days ago, my friend Daru showed me a magazine article titled Girl Genius Gives Lecture in Akihabara. The article was about a 17-year-old girl who had just graduated from an American university. Her thesis was even published in a major scientific journal. Girl Genius, Makise Kurisu. I recognize the stubborn-looking girl from her photograph. She's even wearing the exact same scowl. What business could such a genius have with me? She takes a quick look around the room, then turns back to me with a stern expression.\n",
    "\n",
    "Kurisu: Could you come with me for a moment?\n",
    "\n",
    "UNSPOKEN: What's with the attitude? She's obviously not staff, and there's no way that the Makise Kurisu would be working with someone like Doctor Nakabachi. Which means... no!\n",
    "\n",
    "Okabe: Y-you're with the Organization!?\n",
    "\n",
    "Kurisu: Huh?\n",
    "\n",
    "Okabe: If their tendrils have gotten this far, then I've made a grave mistake.\n",
    "\n",
    "Kurisu: Stop fooling around and come with me.\n",
    "\n",
    "UNSPOKEN: My outburst has already attracted too much attention. Nakabachi, in particular, looks like he wants to rip my head off. It must be mortifying to be exposed as a fraud by a bright young man like myself. Anyway, I mustn't draw any more attention to myself. If the Organization gets wind of my presence here, it could endanger Mayuri -- to say nothing of these ignorant civilians. I let Makise Kurisu lead me out of the assembly hall.\n",
    "\\\"\\\"\\\"\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\" : \"assistant\",\n",
    "        \"content\": \"\"\"Plan: Okabe is the main speaker for most of this scene, passionately accusing Nakabachi of plagiarism. His lines should be filled with emotion and conviction. Towards the end of the scene, he becomes more cautious and wary when interacting with Kurisu. His actions should reflect this change in demeanor. Kurisu on the other hand, remains calm and collected throughout, her actions should reflect her confusion and curiosity about Okabe's behavior. I will be careful to ensure all UNSPOKEN lines are either incorporated into a character's line, or are removed. It makes sense to drop UNSPOKEN lines that are only exposition.\n",
    "\n",
    "Roleplay:\n",
    "\n",
    "Okabe: \"Who the hell am I!?\" *I stand tall, pointing an accusing finger at the man on the podium.* \"Someone who knows you for a fraud, that's who! You stole your theory from John Titor! And you call yourself an inventor!?\" \n",
    "\n",
    "Nakabachi: \"S-someone throw this man out!\" *He stammers, nervously looking at the crowd for support.*\n",
    "\n",
    "Okabe: \"You're the one we should throw out, Doctor!\" *I take a step forward, my voice ringing out in the silent room.* \"Have you no shame!? You have no right to call yourself an inventor!\"\n",
    "\n",
    "Nakabachi: \"Shut your mouth, you little pest!\" *He points a shaking finger at me, his face red with anger.*\n",
    "\n",
    "Kurisu: *Just then, she hand grabs my arm from behind.* \n",
    "\n",
    "Okabe: *I whip around, ready to face another adversary.* \"Unhand me, you... huh?\" *My words falter as I find myself looking into the eyes of a young girl. Recognition dawns on me as I realize who she is.* \"Ah...\"\n",
    "\n",
    "Kurisu: \"Could you come with me for a moment?\" *She asks, her gaze stern and unyielding.*\n",
    "\n",
    "Okabe: \"Y-you're with the Organization!?\" *I step back, my eyes widening in shock and suspicion.*\n",
    "\n",
    "Kurisu: \"Huh?\" *Her brows furrow in confusion, clearly not understanding your reaction.*\n",
    "\n",
    "Okabe: \"If their tendrils have gotten this far, then I've made a grave mistake.\" *I clutch my coat's lapel dramatically, scanning the room for potential threats.*\n",
    "\n",
    "Kurisu: \"Stop fooling around and come with me.\" *She insists, her patience clearly wearing thin.*\n",
    "\n",
    "Okabe: *Seeing no other option, I allow her to lead me away from the crowd.*\"\"\"\n",
    "    },]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_tokens_of_conv(conv):\n",
    "#     \"\"\"Gets the number of tokens in a conversation\"\"\"\n",
    "#     return len(tokenizer.encode(' '.join([d[1] for d in conv[-1]])))\n",
    "\n",
    "# # training_data_conversations_filtered[1][-1]\n",
    "\n",
    "# get_tokens_of_conv(training_data_conversations_filtered[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\n\\n'.join([f'{speaker}: {line}' for speaker, line in training_data_conversations_filtered[1][-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_conversation(training_data_example, destination_directory, example_index):\n",
    "    full_conversation = training_data_example[-1]\n",
    "    context = '\\n\\n'.join([f'{speaker}: {line}' for speaker, line in full_conversation])\n",
    "\n",
    "    scenario = scenarios[example_index]\n",
    "\n",
    "    if not os.path.exists(os.path.join(destination_directory, f'{example_index:03d}_cot_debug.txt')):\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4\",\n",
    "            temperature=0.7,\n",
    "            # top_p=0.9,\n",
    "            messages= annotation_prompt+ [{\n",
    "                \"role\" : \"user\",\n",
    "            \"content\" : f\"\"\"Scenario/setting: \\\"\\\"\\\"{scenario}\\\"\\\"\\\"\n",
    "\n",
    "Dialogue for reformatting: \n",
    "\\\"\\\"\\\"\n",
    "{context.replace(\"Rintaro:\", \"Okabe:\")}\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "Remember:\n",
    "1. Lines from UNSPOKEN represent narration of actions or thoughts from Rintaro's POV. If it makes sense for one of these to be turned into an *action* by a character, do so.\n",
    "2. Write compellingly. You can add actions (BUT NOT VOICELINES) to characters that weren't there before so long as they don't break the continuity of the scene, if it makes your writing more compelling.\n",
    "3. Don't forget to plan out your response first. \n",
    "4. Don't leave any UNSPOKEN lines on lines by themselves; all actions and narrations must be part of a character's line.\n",
    "5. Instead of changing any lines characters say, you will use actions to elegantly tie the scene together (but absolutely do not change any lines characters say).\n",
    "6. Be sure to get the speaker of any given line right, I've seen a few cases where you accidentally switch who is saying a line and that messes up the whole scene.\n",
    "7. Add actions to every line you can, even near the end, and even if it's short.\n",
    "8. Be sure to cover the entire scene, not skipping anything, regardless of the content of the scene. If a character: says it, you MUST include it in your output.\n",
    "9. Every line you write in the roleplay must have a Character: saying it.\n",
    "\"\"\"\n",
    "            }]\n",
    "        )\n",
    "    \n",
    "        annotation = response['choices'][0]['message']['content']\n",
    "\n",
    "        filename_cot_debug = os.path.join(destination_directory, f'{example_index:03d}_cot_debug.txt') # I'm paying for the tokens, I damn well want to see them\n",
    "        try:\n",
    "            annotation = re.search('Roleplay:(.*)', annotation, re.DOTALL).group(1)\n",
    "\n",
    "            # Write the scenario to the file\n",
    "            with open(filename_cot_debug, 'w') as f_1:\n",
    "                f_1.write(annotation)\n",
    "\n",
    "            # Assume \"Scenario:\\n\" is followed by the actual scenario\n",
    "\n",
    "            # Create a filename based on the example index\n",
    "            filename = os.path.join(destination_directory, f'{example_index:03d}.txt')\n",
    "\n",
    "            # Write the scenario to the file\n",
    "            with open(filename, 'w') as f_2:\n",
    "                f_2.write(annotation)\n",
    "        except:\n",
    "            print(\"ERROR in regex, GPT probably screwed up\")\n",
    "    else:\n",
    "        print(f\"Skipping {example_index:03d} because it already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping 000 because it already exists.\n",
      "Skipping 001 because it already exists.\n",
      "Skipping 002 because it already exists.\n",
      "Skipping 003 because it already exists.\n",
      "Skipping 004 because it already exists.\n",
      "Skipping 005 because it already exists.\n",
      "Skipping 006 because it already exists.\n",
      "Skipping 007 because it already exists.\n",
      "Skipping 008 because it already exists.\n",
      "Skipping 009 because it already exists.\n",
      "Skipping 010 because it already exists.\n",
      "Skipping 011 because it already exists.\n",
      "Skipping 012 because it already exists.\n",
      "Skipping 013 because it already exists.\n",
      "Skipping 014 because it already exists.\n",
      "Skipping 015 because it already exists.\n",
      "Skipping 016 because it already exists.\n",
      "Skipping 017 because it already exists.\n",
      "Skipping 018 because it already exists.\n",
      "Skipping 019 because it already exists.\n",
      "Skipping 020 because it already exists.\n",
      "Skipping 021 because it already exists.\n",
      "Skipping 022 because it already exists.\n",
      "Skipping 023 because it already exists.\n",
      "Skipping 024 because it already exists.\n",
      "Skipping 025 because it already exists.\n",
      "Skipping 026 because it already exists.\n",
      "Skipping 027 because it already exists.\n",
      "Skipping 028 because it already exists.\n",
      "Skipping 029 because it already exists.\n",
      "Skipping 030 because it already exists.\n",
      "Skipping 031 because it already exists.\n",
      "Skipping 032 because it already exists.\n",
      "Skipping 033 because it already exists.\n",
      "Skipping 034 because it already exists.\n",
      "Skipping 035 because it already exists.\n",
      "Skipping 036 because it already exists.\n",
      "Skipping 037 because it already exists.\n",
      "Skipping 038 because it already exists.\n",
      "Skipping 039 because it already exists.\n",
      "Skipping 040 because it already exists.\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "You exceeded your current quota, please check your plan and billing details.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create annotated training examples (same # of them as training examples and scenarios)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, example \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(training_data_conversations_filtered):\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mannotate_conversation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mannotated_convs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Create annotated training examples (same # of them as training examples and scenarios)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, example \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(training_data_conversations_filtered):\n",
      "Cell \u001b[0;32mIn[46], line 8\u001b[0m, in \u001b[0;36mannotate_conversation\u001b[0;34m(training_data_example, destination_directory, example_index)\u001b[0m\n\u001b[1;32m      5\u001b[0m     scenario \u001b[38;5;241m=\u001b[39m scenarios[example_index]\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(destination_directory, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexample_index\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m03d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_cot_debug.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[0;32m----> 8\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# top_p=0.9,\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mannotation_prompt\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[38;5;124;43mScenario/setting: \u001b[39;49m\u001b[38;5;130;43;01m\\\"\u001b[39;49;00m\u001b[38;5;130;43;01m\\\"\u001b[39;49;00m\u001b[38;5;130;43;01m\\\"\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mscenario\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;130;43;01m\\\"\u001b[39;49;00m\u001b[38;5;130;43;01m\\\"\u001b[39;49;00m\u001b[38;5;130;43;01m\\\"\u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m \n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;43mDialogue for reformatting: \u001b[39;49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;130;43;01m\\\"\u001b[39;49;00m\u001b[38;5;130;43;01m\\\"\u001b[39;49;00m\u001b[38;5;130;43;01m\\\"\u001b[39;49;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRintaro:\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOkabe:\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;130;43;01m\\\"\u001b[39;49;00m\u001b[38;5;130;43;01m\\\"\u001b[39;49;00m\u001b[38;5;130;43;01m\\\"\u001b[39;49;00m\n\u001b[1;32m     20\u001b[0m \n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;43mRemember:\u001b[39;49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;43m1. Lines from UNSPOKEN represent narration of actions or thoughts from Rintaro\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms POV. If it makes sense for one of these to be turned into an *action* by a character, do so.\u001b[39;49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;43m2. Write compellingly. You can add actions (BUT NOT VOICELINES) to characters that weren\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mt there before so long as they don\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mt break the continuity of the scene, if it makes your writing more compelling.\u001b[39;49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;43m3. Don\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mt forget to plan out your response first. \u001b[39;49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;43m4. Don\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mt leave any UNSPOKEN lines on lines by themselves; all actions and narrations must be part of a character\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms line.\u001b[39;49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;43m5. Instead of changing any lines characters say, you will use actions to elegantly tie the scene together (but absolutely do not change any lines characters say).\u001b[39;49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;43m6. Be sure to get the speaker of any given line right, I\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mve seen a few cases where you accidentally switch who is saying a line and that messes up the whole scene.\u001b[39;49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;43m7. Add actions to every line you can, even near the end, and even if it\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms short.\u001b[39;49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;43m8. Be sure to cover the entire scene, not skipping anything, regardless of the content of the scene. If a character: says it, you MUST include it in your output.\u001b[39;49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;43m9. Every line you write in the roleplay must have a Character: saying it.\u001b[39;49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[1;32m     32\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m         annotation \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     37\u001b[0m         filename_cot_debug \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(destination_directory, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexample_index\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m03d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_cot_debug.txt\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# I'm paying for the tokens, I damn well want to see them\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/openai/api_requestor.py:230\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    210\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    211\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    218\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    219\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    220\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    221\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    222\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    228\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    229\u001b[0m     )\n\u001b[0;32m--> 230\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    231\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/openai/api_requestor.py:624\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    616\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    617\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    618\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    619\u001b[0m         )\n\u001b[1;32m    620\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    621\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    623\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 624\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    625\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    626\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    627\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    628\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    629\u001b[0m         ),\n\u001b[1;32m    630\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    631\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/openai/api_requestor.py:687\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    685\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    686\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 687\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    688\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    689\u001b[0m     )\n\u001b[1;32m    690\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details."
     ]
    }
   ],
   "source": [
    "# Create annotated training examples (same # of them as training examples and scenarios)\n",
    "for idx, example in enumerate(training_data_conversations_filtered):\n",
    "    annotate_conversation(example, 'annotated_convs', idx)\n",
    "\n",
    "# Create annotated training examples (same # of them as training examples and scenarios)\n",
    "for idx, example in enumerate(training_data_conversations_filtered):\n",
    "    annotate_conversation(example, 'annotated_convs', idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'annotated_convs/003.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 18\u001b[0m\n\u001b[1;32m     14\u001b[0m             annotated_conversation_list\u001b[39m.\u001b[39mappend(script_tuples)\n\u001b[1;32m     16\u001b[0m     \u001b[39mreturn\u001b[39;00m annotated_conversation_list\n\u001b[0;32m---> 18\u001b[0m annotated_conversations \u001b[39m=\u001b[39m make_annotated_conversation_list(training_data_conversations)\n",
      "Cell \u001b[0;32mIn[79], line 7\u001b[0m, in \u001b[0;36mmake_annotated_conversation_list\u001b[0;34m(training_data_conversations)\u001b[0m\n\u001b[1;32m      5\u001b[0m annotated_conversation_list \u001b[39m=\u001b[39m []\n\u001b[1;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m idx, content \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(training_data_conversations):\n\u001b[0;32m----> 7\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mannotated_convs/\u001b[39;49m\u001b[39m{\u001b[39;49;00midx\u001b[39m:\u001b[39;49;00m\u001b[39m03d\u001b[39;49m\u001b[39m}\u001b[39;49;00m\u001b[39m.txt\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m      8\u001b[0m         \u001b[39m# Split the cleaned_script into lines and filter out empty lines\u001b[39;00m\n\u001b[1;32m      9\u001b[0m         lines \u001b[39m=\u001b[39m [line\u001b[39m.\u001b[39mstrip() \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m f\u001b[39m.\u001b[39mread()\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m) \u001b[39mif\u001b[39;00m line\u001b[39m.\u001b[39mstrip()]\n\u001b[1;32m     10\u001b[0m         \u001b[39m# Process each line to make a tuple of (speaker, dialogue)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mlp_39/lib/python3.9/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'annotated_convs/003.txt'"
     ]
    }
   ],
   "source": [
    "# Get annotated conversations back into notebook data from files\n",
    "\n",
    "# # read off every annotated conversation, and make a list of them that lines up with the training data\n",
    "annotated_conversations = read_all_dialogues(\"./annotated_convs\")\n",
    "annotated_conversations[0]\n",
    "\n",
    "processed_annotated_conversations = list(map(call_multiple_processors,annotated_conversations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', '')], [('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', ''), ('UNSPOKEN', '')]]\n"
     ]
    }
   ],
   "source": [
    "print(annotated_conversations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whole process text loop again, turn into tuple list\n",
    "# Create training examples (again)\n",
    "training_data_conversations_annotated = list(map(generate_training_examples, annotated_conversations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper that creates JSON object for a training example at a certain index (annotated history, annotated completion, scenario)\n",
    "def create_json_object(training_data_example, annotated_conversation, scenario, example_index):\n",
    "    return { # or something like this\n",
    "        \"history\": '\\n'.join([f'{speaker}: {line}' for speaker, line in training_data_example]),\n",
    "        \"completion\": '\\n'.join([f'{speaker}: {line}' for speaker, line in annotated_conversation]),\n",
    "        \"scenario\": scenario,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T-List to training examples, concatenate, then loop to write json objects with scenario and annotated training example chat history and completion target (for each example) TO FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('mlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4976e0179d97dd6d59b1329a76e601e17b789c2571b41c8b57f5fd69821c0dd3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
